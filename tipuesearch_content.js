var tipuesearch = {"pages":[{"title":"Schneckenkragen","text":"Besonders in diesem Jahr, aber zumindest in meinem Garten jedes Jahr, sind Schnecken ein großes Problem für Hobbygärtner. Man setzt die liebevoll vorgezogenen Pflanzen von der Fenterbank in das Beet, nur um am nächsten Tag zu sehen, dass außer Schleimspuren nichts geblieben ist. Es gibt eine Reihe Hausmittel, die helfen sollen. Praktischerweise im Wikipedia-Artikel zur Schneckenbekämpfung zusammengefasst: Bannkreise aus Eierschalen oder Kaffeepulver Bierfallen, die alle Schnecken aus der Nachbarschaft einladen Kupfer, das nicht nur für Schnecken giftig ist Laufenten — immerhin werden die Pflanzen dann nicht mehr von Schnecken gefressen Drei dieser vier Strategien haben außerdem den Nachteil, dass sie nicht nur die Wegschnecken bekämpfen, die für die meisten Fraßschäden verantwortlich sind, sondern alle Schnecken. Tatsächlich sind Schnecken mit Gehäuse keine Gefahr für die Nutzpflanzen — im Gegenteil: laut des Wikipedia-Artikels gibt es anscheindend eher den Zusammenhang, dass eine große Weinbergschneckenpopulation mit eher kleinen Populationen der schädlichen Wegschnecke korreliert ist. Und auch nicht alle Nacktschnecken sind schädlich! Meine Lieblingsnacktschnecke, der Tigerschnegel , frisst nicht nur Schneckeneier, sondern sogar ausgewachsene Exemplare. Der Schneckenkragen In meinem Garten hat sich der Schneckenkragen bewährt. Das ist ein hohler Zylinder mit Widerhaken nach außen. Einfacher an einem Bild zu zeigen als zu beschreiben. Dort, wo die 3D-gedruckte Schnecke abgebildet ist, sollte keine Schnecke mehr hingelangen können. Man steckt ihn einfach mit einer leicht drehenden Bewegung etwa 2 cm tief in den Boden. Dabei ist unbedingt zu beachten, dass andere Pflanzen nicht zu dicht am Kragen stehen dürfen, da die Schnecken sie ansonsten als Brücken nutzen können. Und natürlich sollte man sicherstellen, dass sich keine Schnecke im Inneren des Schneckenkragens befindet. Sie verstecken sich gerne unter Steinchen oder Ästen. Am besten lockert man den Boden innerhalb des Scheckenkragens daher einmal auf und befördert dabei zutage tretende Schnecken heraus. Auch wenn man alles beachtet, kann es sein, dass in der Erde noch Schneckeneier sind, die innerhalb des Kragens schlüpfen. Man muss also dennoch regelmäßig nachschauen. Aber zumindest in meinem Garten, ist der Unterschied zwischen geschützten und ungeschützten Pflanzen gewaltig. Die Funktionsweise ist anscheinend nicht ganz klar. Erklärungsansätze, die ich finden konnte, sind, dass der Wechsel von \"senkrecht nach oben\" zu \"45° nach unten\" nicht im Verhaltensrepertoire von Schnecken enthalten ist. Und dass der Kragen dazu führt, dass die Schnecken auf dem Weg nach oben den Geruch der Pflanzen verlieren und dann verwirrt wieder nach unten kriechen. Upgrade Nach meinen (leidvollen) Erfahrungen finden in besonders schneckenreichen Beeten bei feuchtem Wetter einige Schnecken dennoch in den Kragen. Das scheint daran zu liegen, dass sich Schnecken in den Knick verkriechen. Von da aus kriechen sie dann später in eine zufällige Richtung — entweder in den Kragen hinein oder wieder herunter. Zumindest vermute ich, dass dies der Mechanismus ist. Wenn die Annahme richtig ist, müssen wir also nur verhindern, dass die Schnecken es sich in dem Knick gemütlich machen. In der Einleitung hatte ich kurz erwähnt, dass Schnecken Kupfer vermeiden, denn Kupfer ist giftig für Weichtiere (sowie Einzeller und viele Wassertiere). Der Mechanismus ist anscheinend, dass Schneckenschleim leicht sauer ist und bei Kontakt leicht Kupferionen löst, die für die Schnecke giftig und unangenehm sind. Dafür muss die Schnecke allerdings ausreichend lange Kontakt mit dem Kupfer haben, sodass ein Kupferdraht, der um das Beet liegt, keine Schnecken abschreckt. Wir können aber das Kupfer nutzen, um die Schnecken davon abzuhalten, sich in dem Knick aufzuhalten, indem wir einen Streifen Kupferfolie möglichst weit oben um den Kragen kleben. Gleichzeitig ist das Kupfer dort unter dem \"Dach\" vor Regen geschützt, sodass die Exposition der Umgebung minimiert wird. Upgrade 2 — Electric Boogaloo Wenn dies immer noch nicht ausreicht, um die Pflanzen hinreichend zu schützen, gibt es noch die Möglichkeit den Kragen zu einem Elektrozaun zu modifizieren. Dazu klebt man zwei Streifen Kupferband um den Kragen, sodass sie sich nicht berühren und schließt sie an eine 9 V Batterie an. Um die 9 V Batterie zu halten, habe ich eine Variante des Kragens mit einer Halterung und einer Öffnung für die Kabel erstellt. Damit die Batterie nicht nass wird, sollte man die Oberseite der Öffnung mit Silikonkleber abdichten. Wenn Schnecken nun hochkriechen, schließen sie den Stromkreis und bekommen einen Stromschlag. In der Regel sollten sie sich zurückziehen oder betäubt werden und herunterfallen. Falls diese Methode zu lethal für die Schnecken ist, kann noch ein Widerstand in Reihe an einen der Pole gelötet werden. Fertigung Die Fertigung gelingt mit einem 3D-Drucker. Ich habe hierfür ein einfaches Modell designt . Leider benötigt ein hinreichend großer Schneckenkragen, der stabil genug ist, um ihn in den Boden drücken zu können, relativ viel Filament. Bei dem Filament sollte man darauf achten, dass es UV -beständig ist, wie PETG oder ASA . Das sorgt dafür, dass er in der Sonne nicht spröde wird und man ihn viele Jahre nutzen kann.","tags":"Misc","url":"https://blog.schawe.me/schneckenkragen.html","loc":"https://blog.schawe.me/schneckenkragen.html"},{"title":"Osteralbtraum","text":"Ostern ist ein Feiertag, dessen Zeitpunkt mit einer Regel festgelegt wird, die unnötig kompliziert scheint. Der erste Sonntag nach dem ersten Vollmond im Frühling. Den meisten bleibt da als Lösung nicht viel mehr übrig als in einem Kalender nachzusehen welches Datum es denn wohl ist und sich auf den Kalenderhersteller zu verlassen. Aber nicht mit mir! Ich werde es Big-Calendar zeigen und hier die geheime Formel veröffentlichen, mit der man das Osterdatum berechnet! from datetime import date def easter ( year : int ) -> date : y = year g = y % 19 + 1 # golden number c = y // 100 + 1 # century x = ( 3 * c ) // 4 - 12 # correction: dropped leap years z = ( 8 * c + 5 ) // 25 - 5 # correction: synchronize with moon's orbit d = ( 5 * y ) // 4 - x - 10 # find sunday e = ( 11 * g + 20 + z - x ) % 30 # epact if e == 25 and g > 11 or e == 24 : e += 1 n = 44 - e # full moon in march if n < 21 : n += 30 n = n + 7 - ( d + n ) % 7 # advance to next sunday month , day = ( 4 , n - 31 ) if n > 31 else ( 3 , n ) return date ( year , month , day ) Mir persönlich gefällt besonders gut, dass jede Zeile schlimmer ist als die vorherige. Dieser Algorithmus ist übrigens von Lilius und Clavius Ende des 16. Jahrunderts entwickelt worden. Ich bin durch eine Erwähnung in einer Übungsaufgabe in Donald Knuths The Art of Computer Programming 1 (Third edition, S. 159f) darauf gestoßen.","tags":"Code","url":"https://blog.schawe.me/easter.html","loc":"https://blog.schawe.me/easter.html"},{"title":"pirShow","text":"Alte Monitore sind zu Schade zum Entsorgen. Als Upcycling habe ich deshalb einen alten Monitor zu einem digitalen Bilderrahmen in meinem Flur umfunktioniert. Sinnvollerweise sollte er natürlich nur dann ein Bild zeigen, wenn auch jemand da ist, der es betrachten kann. Hier möchte ich einmal kurz beschreiben, wie ich einen Raspberry Pi, einen passiven Bewegungssensor und etwas Python-Code zu diesem Zweck benutze. Bildquellen definieren Die Hauptfunktionalität eines digitalen Bilderrahmens ist es natürlich Bilder anzuzeigen. Diese Bilder sollen aus mehreren Quellen zufällig ausgewählt werden. Dabei habe ich mir einige Flickr-Accounts über Raumfahrt und meine Twitter-Bots ausgesucht. Zuerst brauchen wir also etwas Code, um die Bilder herunterzuladen. def flickr ( user_id ): import flickrapi from keys_and_secrets import keys_and_secrets url_template = 'http://farm %(farm_id)s .staticflickr.com/ %(server_id)s / %(photo_id)s _ %(secret)s _b.jpg' def url_for_photo ( p ): return url_template % { 'server_id' : p . get ( 'server' ), 'farm_id' : p . get ( 'farm' ), 'photo_id' : p . get ( 'id' ), 'secret' : p . get ( 'secret' ), } flickr = flickrapi . FlickrAPI ( keys_and_secrets [ \"flickr_key\" ], keys_and_secrets [ \"flickr_secret\" ]) photo = random . choice ( flickr . photos . search ( user_id = user_id , per_page = 500 )[ 0 ]) purl = url_for_photo ( photo ) title = photo . get ( 'title' ) fname = save_image ( purl , title ) return fname def twitter ( atname ): import tweepy from keys_and_secrets import keys_and_secrets auth = tweepy . OAuthHandler ( keys_and_secrets [ \"consumer_key\" ], keys_and_secrets [ \"consumer_secret\" ]) auth . set_access_token ( keys_and_secrets [ \"access_token_key\" ], keys_and_secrets [ \"access_token_secret\" ]) api = tweepy . API ( auth ) tweets = api . user_timeline ( atname , count = 30 ) urls = [] for i in tweets : if \"media\" in i . entities : for j in i . entities [ \"media\" ]: url = j [ \"media_url\" ] if \"thumb\" not in url : urls . append (( url , i . id_str )) purl , title = random . choice ( urls ) fname = save_image ( purl , title ) return fname Dann bauen wir uns einen praktischen Decorator, den wir nutzen, um unterschiedliche Accounts als Bildquellen zu registrieren. sources = {} def source ( source_name ): def source_decorator ( func ): sources [ source_name ] = func @wraps ( func ) def func_wrapper ( * args , ** kwargs ): return func ( * args , ** kwargs ) return func_wrapper return source_decorator @source ( \"apollo\" ) def apollo (): return flickr ( \"projectapolloarchive\" ) @source ( \"randomGraphs\" ) def randomGraphs (): return twitter ( \"@randomGraphs\" ) @source ( \"AFractalADay\" ) def AFractalADay (): return twitter ( \"@AFractalADay\" ) Dies ermöglicht es dann sehr komfortabel zufällige Bilder herunterzuladen und anzuzeigen. def random_image (): image_getter = random . choice ( list ( sources . values ())) fname = image_getter () # show image # skipped terminating old instance of feh and aquiring a mutex env = os . environ env [ \"DISPLAY\" ] = \":0\" VIEWER = subprocess . Popen ( [ \"feh\" , \"-FZYx\" , fname ], env = env , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) Monitor ein- und ausschalten Jetzt, da wir Bilder zum Anzeigen haben, müssen wir den Monitor ein- und ausschalten, damit man sie sieht bzw. damit wir nicht sinnlos Strom verbrauchen. Hier rufen wir wieder Kommandozeilen-Werkzeuge auf: tvservice schaltet den Standby-Modus des Monitors um und chvt wechselt einmal vom X-Server weg und wieder zurück, was den Bildschirmschoner beendet. from threading import Timer , Lock MUTEX = Lock () STATE = False def monitor ( status ): global STATE # needs to run as root # make sure that sudo will not ask for a password for these commands # e.g. use visudo to add # piruser ALL=(ALL) NOPASSWD: /usr/bin/tvservice, /bin/chvt with MUTEX : if status : if not STATE : os . system ( \"sudo tvservice -p; sleep 0.5; sudo chvt 6; sleep 0.5; sudo chvt 7\" ) STATE = True else : if STATE : os . system ( \"sudo tvservice -o\" ) # download and show the next image random_image () STATE = False PIR Jetzt müssen wir diese Funktionalität nur noch durch einen Bewegungssensor auslösen. Dazu schließen wir einfach einen Pyroelektrischen Infrarot Sensor ( PIR ) an beispielsweise Pin 23 und sagen dem Raspberry, dass er dort horchen soll, ob ein Signal anliegt. import RPi.GPIO as GPIO SENSOR_PIN = 23 GPIO . setmode ( GPIO . BCM ) GPIO . setup ( SENSOR_PIN , GPIO . IN ) if __name__ == \"__main__\" : GPIO . add_event_detect ( SENSOR_PIN , GPIO . RISING , callback = pir_callback ) Der pir_callback schaltet dann einfach den Monitor an und startet einen Timer, der den Monitor wieder ausstellt (dieser Timer wird abgebrochen sobald der Callback erneut aufgerufen wird, damit der Monitor an bleibt, solange jemand das Bild betrachtet.) Der pir_callback sendet außerdem auch eine MQTT -Nachricht, um die Bewegungsmeldung auch für Home-Assistant-Automatisierungen zu nutzen, sodass die Beleuchtung im Flur nach Sonnenuntergang nun auch durch Bewegungen ausgelöst wird.","tags":"Code","url":"https://blog.schawe.me/pirshow.html","loc":"https://blog.schawe.me/pirshow.html"},{"title":"Künstliche Kunst","text":"Seit der Vorstellung von DALL -E Anfang 2021 sind Text-zu-Bild-Programme im Bewusstsein der Öffentlichkeit angekommen. DALL -E 2.0 und Midjourney haben immer wieder mit interessanten, verrückten und überraschend gut aussehenden Bildern auf sich aufmerksam gemacht, die aber immer nur in sehr begrenztem Umfang von ausgewählten Usern auf Servern der Betreibern generiert werden konnten. Aber seit August 2022 gibt es mit Stable Diffusion das erste hochwertige Text-zu-Bild-Modell, dessen Neuronales Netzwerk offen ist und von jedem (der eine Grafikkarte mit genügend Speicher hat) auf dem eigenen Computer genutzt werden kann! Die grundlegende Funktionsweise ist, dass man dem Modell eine Bildbeschreibung, sogenannte Prompts , gibt und das Modell versucht ein Bild zu rendern, das möglichst gut zu der Beschreibung passt. Die Kunst liegt nun darin, die Bildbeschreibung so zu formulieren, dass das resultierende Bild möglichst gut wird. Wenn wir wissen wollen, wie so eine künstliche Intelligenz überhaupt aussieht, können wir Stable Diffusion darum bitten uns ein Bild von einer zu malen mit dem Prompt \"a painting of an artificial intelligence\": In der Community findet man häufig Prompts, die mit vielen Adjektiven (wie \"intricate\" oder \"highly detailed\") oder Künstlernamen (vor allem \"Greg Rutkowski\") gespickt sind. Für mich persönlich klingt es nach zu viel Arbeit eine solche Liste von Schlüsselworten an eine knappe Bildbeschreibung zu hängen — ich benutze schließlich eine künstliche Intelligenz, die Bilder zeichnet, damit ich wenig Arbeit habe! Die offensichtliche Lösung für dieses Problem ist es natürlich ein Sprachmodell zu benutzen, um Prompts zu generieren. Glücklicherweise gibt es mit lexica.art eine Datenbank von Prompts, die man nutzen kann, um ein GPT -2 Modell zu finetunen. So kann man GPT -2 Modell mit \"four dimensional space whale\" füttern, GPT -2 macht daraus den Prompt \"four dimensional space whale, with recursive spiral eyes, concept art, high detail, intimidating, cinematic, Artstation trending, octane render\", der von Stable Diffusion zu diesem Bild gerendert wird: Und damit ich auch keine Arbeit damit habe, die Bilder selbst zu generieren, habe ich einen Twitter-Bot damit beauftragt täglich ein lovecraft'sches Bild zu tweeten: @ACthulhuADay . Der Glue-Code, der diesen text2prompt2image-Ablauf implementiert (also hauptsächlich Modelle von Huggingface herunterlädt) und diesen Bot antreibt, findet sich auf Github .","tags":"Code","url":"https://blog.schawe.me/kunstliche-kunst.html","loc":"https://blog.schawe.me/kunstliche-kunst.html"},{"title":"Analog-Digital-Analoges Thermometer","text":"Ich habe mir ein analoges Voltmeter zugelegt und möchte es als Thermometer benutzen. Da der Widerstand von Metallen mit der Temperatur steigt, kann man Temperatur relativ gut messen, indem man einen kalibrierten Widerstand misst. Daher kann man theoretisch mit einem Multimeter auch die Temperatur messen. (In der Praxis wird dies bei Multimetern allerdings in der Regel mithilfe eines anderen Effektes erledigt.) Da ich mir aber keine Gedanken darüber machen möchte, wie ich eine Schaltung aussehen müsste, um $15°\\mathrm{C}$ in $1.5 \\mathrm{V}$ umzusetzen (vielleicht würde eine Brückenschaltung funktionieren?), wähle ich den einfachen Weg mit einer Reihe integrierter Schaltkreise und einem Microcontroller. Hier ist ein günstiger DS18B20 Temperatursensor, der von einem ESP8266 ausgelesen wird. Dieser steuert dann einen MCP4725 Digital-Analog-Wandler so an, dass er eine Spannung ausgibt, deren Wert in Volt ein Zehntel der gemessenen Temperatur ist. Diese Spannung wird dann von meinem alten Voltmeter gemessen und angezeigt. Hier ist es also gerade $24°\\mathrm{C}$. Hier ist übrigens der simple Code, der beispielsweise mit der Arduino IDE auf einen ESP8266 geflasht werden kann: #include <Wire.h> #include <Adafruit_MCP4725.h> #include <OneWire.h> #include <DallasTemperature.h> #define ONE_WIRE_BUS D4 #define MCP4725In A0 Adafruit_MCP4725 MCP4725 ; OneWire oneWire ( ONE_WIRE_BUS ); DallasTemperature DS18B20 ( & oneWire ); void setup () { Serial . begin ( 9600 ); DS18B20 . begin (); // 0x60 is the I2C address of my MCP4725A0 MCP4725 . begin ( 0x60 ); } float getTemperature () { float temp ; do { DS18B20 . requestTemperatures (); temp = DS18B20 . getTempCByIndex ( 0 ); delay ( 100 ); } while ( temp == 85.0 || temp == ( -127.0 )); return temp ; } void setVoltage ( float value ) { value /= 10 ; float voltageOut = value * 4096 / 3.3 ; MCP4725 . setVoltage ( voltageOut , false ); // read it for testing and maybe calibrating int adcInput = analogRead ( MCP4725In ); float voltageIn = ( adcInput * 3.3 ) / 1024.0 ; Serial . print ( \"Expected Voltage: \" ); Serial . println ( value , 3 ); Serial . print ( \"Measured Voltage: \" ); Serial . println ( voltageIn , 3 ); } void loop () { float temperature = getTemperature (); setVoltage ( temperature ); // send temperature to the serial console dtostrf ( temperature , 2 , 2 , temperatureString ); Serial . println ( temperatureString ); delay ( 1e3 ); }","tags":"Tech","url":"https://blog.schawe.me/analog-digital-analoges-thermometer.html","loc":"https://blog.schawe.me/analog-digital-analoges-thermometer.html"},{"title":"Heimkinoautomatisierung","text":"Ich habe seit langem einen Beamer statt eines Fernsehers, was einige Vorteile mit sich bringt: ein sehr großes Bild, kein im Weg stehender Fernseher und die perfekte Motivation Hausautomatisierung in Angriff zu nehmen. Schließlich ist der Ablauf, bevor ein Film starten kann, durchaus aufwendig: Die Jalousien werden geschlossen. Die Leinwand fährt herunter. Der AV -Receiver wird angeschaltet. Der Beamer startet. Tatsächlich hatte ich vor Jahren einen selbstgeschriebenen Python-Server auf einem Raspberry Pi aufgesetzt, der diese Steuerung übernommen hat. Aber vor kurzem habe ich ihn ersetzt durch die Anbindung von einem ESP 8266 mittels ESP Home an Home Assistant . In meinem Setup kommt von Infrarot ( IR ) Fernbedienung über 433 MHz Funk ( RF ) und Transistoren, die über Fernbedienungskontakte gelötet sind, bis zu einer seriellen RS232 Schnittstelle alles vor. Es sollte also für jeden Leser etwas dabei sein. Die Jalousien Meine Jalousien wurden ursprünglich per Hand mit einem Gurt geöffnet und geschlossen. Der einfachste Weg solche Rollläden weniger manuell zu machen, sind nachrüstbare Gurtwickler, die die Muskelkraft durch einen Servomotor ersetzen. Ich habe mir einen relativ günstigen elektrischen Gurtwickler mit einer 433 MHz Fernbedienung gekauft. Der Plan war eigentlich mit einem 433 MHz Receiver die Signale aufzuzeichnen und danach mit einem Sender wieder zu schicken. Blöderweise hat sich (unter Verwendung von Audacity als Offline-Oszilloskop) herausgestellt, dass sich das Signal bei jedem Knopfdruck ändert — anscheinend nutzen meine Gurtwickler ein Protokoll mit Schlüssel, was beispielsweise für sicherheitsrelevante Anwendungen wie Garagentore verwendet wird. Die einfache Lösung dafür ist, die Fernbedienung auseinander zu bauen und die Taster, die normalerweise per Hand ausgelöst werden, mit Transistoren zu überbrücken, die dann über GPIO Pins ausgelöst werden können. Und die Konfiguration in ESP Home ist selbsterklärend. output : - platform : gpio id : blinds_up_pin pin : D7 button : - platform : output id : blinds_up name : Jalusinen hoch icon : \"mdi:roller-shade\" output : blinds_up_pin duration : 300ms # skipped blinds down Die Leinwand Motorisierte Leinwände haben oft einen Eingang für einen 3,5 mm Klinkenstecker, den man direkt mit dem Beamer verbinden kann. Leider nicht die Leinwand, die ich habe. Aber halb so schlimm, denn sie hat eine Funkfernbedienung und ich habe ja noch die 433 MHz Hardware, die für die Jalousien gedacht waren. Und tatsächlich nutzt meine Leinwand ein simples Protokoll — aber auf 315 Mhz. Sobald wir also einen 315 MHz Transmitter und Receiver haben, können wir die Codes aufzeichnen und die ESP Home Konfiguration anpassen. Dafür definieren wir einen remote_transmitter für den passenden GPIO Pin und einen switch , der den Code für \"herunter fahren\" sendet, die passende Zeit wartet und dann den Code für \"stopp\" sendet. Eine Stolperfalle ist, dass der Code mittels repeat mehrmals gesendet werden muss. remote_receiver : - id : RF315_Recv pin : number : D5 inverted : yes mode : INPUT_PULLUP dump : all remote_transmitter : - id : RF315 pin : D1 carrier_duty_percent : 100% switch : - platform : template name : Screen icon : \"mdi:projector-screen\" optimistic : true turn_on_action : - remote_transmitter.transmit_rc_switch_raw : transmitter_id : RF315 code : '000110110111100111000100' protocol : 1 repeat : times : 10 wait_time : 0s - delay : 39.0s - remote_transmitter.transmit_rc_switch_raw : transmitter_id : RF315 code : '000110110111100111001000' protocol : 1 repeat : times : 10 wait_time : 0s # turn_off_action skipped Der AV -Receiver Dies ist die erste Komponente, die nach Plan läuft: Der AV -Receiver hat eine IR Fernbedienung und der Hersteller veröffentlicht die Codes sogar selbst, sodass ich mir das Aufzeichnen sparen kann. Falls man diesen Luxus nicht that, kann man an den ESP einen IR Receiver wie einen TSOP 4838 anschließen und mit dem remote_receiver auswerten. Um die Signale zu senden, reicht eine Infrarotdiode, die ich über einen Transistor schalte. Für ESP Home müssen wir einen weiteren remote_transmitter definieren. Damit die Codes über die IR Diode und nicht über den RF Sender verschickt werden, müssen wir dem Transmitter eine Id zuweisen und diese später mit transmitter_id referenzieren. remote_transmitter : - id : IR pin : D2 carrier_duty_percent : 50% button : - platform : template id : av_on name : AV on icon : \"mdi:audio-video\" on_press : - remote_transmitter.transmit_pioneer : transmitter_id : IR rc_code_1 : 0xA51A repeat : times : 2 # skipped other buttons Der Beamer Den Beamer könnte man natürlich auch per IR steuern, aber mein Modell, der BenQ W1070, hat eine RS232 Schnittstelle, die nicht nur etwas zuverlässiger als die Infrarotschnittstelle ist, sondern es auch erlaubt den aktuellen Zustand auszulesen. Dazu können wir bspw. einen MAX3232 an die UART Pins anschließen und die Beispielkonfiguration für den custom text_sensor aus der ESP Home Dokumentation kopieren. logger : # disable logging over uart baud_rate : 0 uart : id : uart_bus tx_pin : 1 rx_pin : 3 # choose same value set in the projector settings baud_rate : 9600 text_sensor : # this needs the .h file from https://esphome.io/cookbook/uart_text_sensor.html - platform : custom lambda : |- auto my_custom_sensor = new UartReadLineSensor(id(uart_bus)); App.register_component(my_custom_sensor); return {my_custom_sensor}; text_sensors : id : \"uart_readline\" switch : - platform : template name : \"Projector Power\" icon : \"mdi:projector\" lambda : |- if (id(uart_readline).state == \"*POW=ON#\") { return true; } else if(id(uart_readline).state == \"*POW=OFF#\") { return false; } else { return {}; } turn_on_action : - uart.write : \"\\r*pow=on#\\r\" turn_off_action : - uart.write : \"\\r*pow=off#\\r\" Fazit Da dies doch eine ganze Menge Komponenten sind, die ich per Jumper-Kabel an den ESP geschlossen habe, ist noch ein Gehäuse nötig. Dazu nutze ich die beste Alternative zu einem 3D-Drucker: Lego! Die Aufhängung des Beamers bietet dabei den optimalen Ort für eine provisorische Befestigung, die nahe am RS232 -Eingang des Beamers ist und einen guten Blick auf den IR -Empfänger des AV -Receivers hat. Die gesamte EPS -Home-Konfigurationsdatei steht auch als GitHub Gist bereit. Das ganze Setup wird abgerundet von einem selbstgebauten Schalter (mit Cherry Blue Switches), um den Kinomodus zu starten und zu beenden, sowie Home-Assistant-Automatisierungen, die das Licht kontrollieren: Licht aus wenn der Film startet, Licht gedimmt, wenn er pausiert.","tags":"Tech","url":"https://blog.schawe.me/heimkinoautomatisierung.html","loc":"https://blog.schawe.me/heimkinoautomatisierung.html"},{"title":"git subtree","text":"Wir alle kennen die Situation: Eine neue Idee, mit der wir unser bestehendes Projekt mit dem Namen alt erweitern, sodass wir sogleich im zugehörigen Repository ein Unterverzeichnis neueIdee anlegen. Die Idee stellt sich dann als so gut heraus, dass sie auch außerhalb des Projektes alt nützlich wäre. Es wäre also sehr sinnvoll ein neues Repository neu anzulegen, das nur den Inhalt des Unterverzeichnisses neueIdee enthalten soll. Tatsächlich scheint dieses Problem wohl so oft vorzukommen, dass es seit 2012 ein extra git Subcommand für diesen Zweck (und etwas kompliziertere Fälle) gibt: git subtree Neues Repository aus einem Unterverzeichnis alt/ ├─ neueIdee/ │ ├─ lib.rs ├─ main.rs Wir wechseln also in das Repository alt führen dort folgendes Kommando aus: git subtree split --prefix = neueIdee/ --branch = nurNeueIdeeBranch Dies erzeugt in diesem Repository zunächst einen neuen Branch nurNeueIdeeBranch , der nur den Inhalt von neueIdee hat — also ein anderes Wurzelverzeichnis. Dieser Branch enthält also eine neu geschriebene History, die nur aus Commits besteht, die (auch) Einfluss auf Dateien unterhalb von neueIdee hatten. Nun können wir unser neues Repository neu anlegen und den soeben erzeugten Branch pullen. cd .. ; mkdir neu ; cd neu git init git pull ../alt nurNeueIdeeBranch Und schon haben wir ein neues Repository, das nur den gewünschten Inhalt hat. alt/ ├─ main.rs neu/ ├─ lib.rs Möglicherweise wollen wir noch einen Commit im alten Repository tätigen, der das neueIdee Unterverzeichnis löscht. Möglicherweise müssen wir im neuen Repository noch Änderungen am Infrastrukturcode vornehmen. Verschieben eines Unterverzeichnisses in ein bestehendes Repository Womöglich fällt uns aber auch auf, dass der Code besser in ein anderes Repository statt eines Neuen passt? Vielleicht weil wir gerade dabei sind unseren Code in einem Monorepo zu sammeln? Auch kein Problem! alt/ ├─ neueIdee/ │ ├─ lib.rs ├─ main.rs monorepo/ ├─ project1/ ├─ project2/ Wir haben oben bereits den nurNeueIdeeBranch erstellt, den wir nun in das Unterverzeichnis guteIdee des Repositorys monorepo einfügen wollen. Auch hier hilft uns wieder git subtree weiter: cd monorepo git branch mitGuterIdeeBranch git checkout mitGuterIdeeBranch git subtree add --prefix = guteIdee/ ../alt nurNeueIdeeBranch Sobald wir uns in dem neuen Branch mitGuterIdeeBranch überzeugt haben, dass alles zu unserer Zufriedenheit geklappt hat und wir möglicherweise noch Infrastrukturcode angepasst haben, können wir den Branch nach main mergen und sind fertig. alt/ ├─ neueIdee/ │ ├─ lib.rs ├─ main.rs monorepo/ ├─ project1/ ├─ project2/ ├─ guteIdee/ │ ├─ lib.rs","tags":"Snip","url":"https://blog.schawe.me/git-subtree.html","loc":"https://blog.schawe.me/git-subtree.html"},{"title":"Convex hulls of random walks in higher dimensions: A large deviation study","text":"Die Frage wie groß das Revier eines Tieres ist, ist in konkreten Fällen für Biologen interessant und dank GPS -Sendern kann man es heutzutage sogar empirisch untersuchen. Aus der Punktwolke der besuchten Orte kann man eine Fläche abschätzen — im einfachsten Fall indem man die konvexe Hülle um alle besuchten Orte zeichnet. Als Physiker sind mir echte Tiere zu kompliziert, sodass ich stattdessen annehme, dass sie punktförmig sind und ihre Bewegung ein Random Walk in einer isotropen Umgebung ist. Also springen meine idealisierten Tiere unabhängig von ihren bisherigen Handlungen zu ihrem nächsten Aufenthaltsort — der Abstand vom aktuellen Punkt ist dabei in jeder Dimension unabhängig und normalverteilt. In jeder Dimension? Ja, genau! Wir wollen schließlich auch das Revierverhalten von vierdimensionalen Space Whales untersuchen. Spaß beiseite, in dieser Veröffentlichung geht es natürlich eher um fundamentale Eigenschaften von Random Walks — einer der einfachsten und deshalb am besten untersuchten Markow-Prozesse. Und zwar im Hinblick auf Large Deviations, die extrem unwahrscheinlichen Ereignisse, die weit jenseits der Möglichkeiten von konventionellen Sampling-Methoden liegen. Details hierzu sind am besten direkt im Artikel oder mit einer Menge Hintergrundinformationen und ausführlicher als für ein Blog angemessen in dem entsprechenden Kapitel und Anhang meiner Dissertation nachzulesen. Insbesondere ist dort auch beschrieben wie die geometrischen Unterprobleme effizient gelöst werden können, auf die wir im Verlauf dieses Blogposts stoßen werden. Das Problem eine konvexe Hülle zu finden ist einerseits einfach zu begreifen, schön geometrisch und sehr gut untersucht. Dadurch sind überraschend viele Algorithmen bekannt, die unterschiedliche Vor- und Nachteile haben. Im Folgenden möchte ich deshalb ein paar Methoden vorstellen, wie man effizient die konvexe Hülle einer Punktmenge bestimmen kann, und dies mit animierten gifs von Punkten und Strichen visualisieren. Der Code zur Erstellung der Visualisierungen ist übrigens in Rust geschrieben und auf GitHub zu finden. Andrew's Monotone Chain In zwei Dimensionen kann man ausnutzen, dass die konvexe Hülle ein Polygon ist, das man durch die Reihenfolge der Eckpunkte definieren kann. Die grundlegende Idee ist also die Punkte im Uhrzeigersinn zu sortieren, in dieser Reihenfolge, mit dem Punkt ganz links startend, alle zu einem Polygon hinzuzufügen und dabei darauf zu achten, dass die drei neusten Punkte des Polygons ein negativ orientiertes Dreieck bilden, also dass sie im \"Uhrzeigersinn drehen\". Wenn das nicht der Fall ist, wird der mittlere Punkt entfernt. Dies ist übrigens die ursprüngliche Variante, der Graham Scan . Andrew verbesserte diesen Algorithmus dadurch, dass nicht im Uhrzeigersinn sortiert werden muss, sondern man lexikographisch nach horizontaler Koordinate (bei Gleichstand entscheidet die vertikale Koordinate) sortiert. Dann bildet dieser Algorithmus die obere Hälfte der Hülle und wenn man ihn rückwärts auf die sortierten Punkte anwendet, die untere Hälfte. Die Komplexität für $n$ Punkte ist somit $\\mathcal{O}(n \\ln n)$ limitiert durch das Sortieren. Jarvis March: Gift Wrapping Ein Geschenk einzupacken ist ein relativ intuitiver Prozess: Wir bewegen das Papier so lange herunter, bis wir auf einen Punkt des Geschenkes treffen, wo es hängen bleibt Dann wickeln wir weiter, bis wir auf den nächsten Punkt stoßen. Dabei streben wir an die konvexe Hülle zu finden, denn sie ist das Optimum möglichst wenig Papier zu verbrauchen während wir die Punktwolke einhüllen, die wir verschenken wollen. Und offenbar klappt das auch in drei Dimensionen! In einem Computer ist es allerdings einfacher das Geschenkpapier von innen aus der Punktwolke heraus nach außen zu falten. Für jede Facette testen wir also jeden der $n$ Punkte in der Punktwolke darauf, ob er links von unserem Stück Geschenkpapier liegt. Wenn ja, falten wir das Papier weiter. Sobald wir alle $n$ Punkte ausprobiert haben, wissen wir, dass das Geschenkpapier an der richtigen Stelle liegt, sodass anfangen können die nächste Facette mit dem Geschenkpapier zu bilden indem wir von innen alle Punkte durchtesten. Interessanterweise müssen wir also für jeden der $h$ Punkte, die zur Hülle gehören $\\mathcal{O}(n)$ Punkte prüfen, sodass die Komplexität abhängig ist vom Ergebnis: $\\mathcal{O}(n h)$ Chan's Algorithm Wir haben also einen $\\mathcal{O}(n \\ln n)$ und einen $\\mathcal{O}(n h)$ Algorithmus kennen gelernt, aber können wir noch besser werden? Ja! $\\mathcal{O}(n \\ln h)$ ist die theoretische untere Komplexitätsgrenze für 2D konvexe Hüllen. Beispielsweise Chans Algorithmus erreicht diese Komplexität mit einem trickreichen zweistufigen Prozess. Zuerst teilt man die Punktwolke in zufällige Untermengen mit jeweils etwa $m$ Punkten ein. Für jede berechnet man die konvexe Hülle, bspw. mit Andrews Algorithmus. Dann benutzt man Jarvis March, um die Hülle zu konstruieren, dabei muss man allerdings nicht mehr alle Punkte durchprobieren, sondern nur noch die Tangenten, die in der Animation mit grünen Strichen gekennzeichnet sind. Die Tangenten kann man für jede der $k = \\lceil \\frac{n}{m} \\rceil$ Sub-Hüllen effizient in $\\mathcal{O}(m)$ bestimmen. Dazu benutzt man einem Algorithmus, der an eine Binärsuche erinnert. Zusammen hat dies also eine Komplexität von $\\mathcal{O}((n+kh) \\ln m)$. Aber ich hatte $\\mathcal{O}(n \\ln h)$ versprochen. Nun, um das zu erreichen, müssen wir einfach nur $m \\approx h$ wählen. Aber wie kommen wir an $h$ bevor wir die Hülle berechnet haben? Der Trick ist, mit einem niedrigen $m$ zu starten, dann nur $m$ Schritte des Jarvis-Teils des Algorithmus durchzuführen und wenn die Hülle dann noch nicht fertig ist $m$ zu erhöhen und es wieder von vorne zu beginnen. Damit dieser iterative Teil des Algorithmus nicht unsere Komplexität erhöht, muss $m$ schnell genug wachsen, was in der Regel durch Quadrieren des alten Werten erreicht wird. QuickHull Zuletzt möchte ich hier noch QuickHull vorstellen, weil dieser Algorithmus meiner Meinung nach einen sehr hübschen rekursiven divide and conquer Ansatz verfolgt — ein bisschen wie QuickSort. In zwei Dimensionen starten wir mit dem Punkt ganz links $A$ und ganz rechts $B$. Dann finden wir den Punkt $C$ der am weitesten entfernt ist von der Strecke $\\overline{ AB }$ und links von der Strecke ist. Diesen Schritt wiederholen wir rekursiv auf den Strecken $\\overline{ AC }$ und $\\overline{ CB }$ (und $\\overline{ BA }$ für die untere Hälfte.) Mehr Dimensionen Aber ich hatte Space Whales versprochen, also können wir uns nicht mit 2D zufrieden geben! Tatsächlich müssen wir schon beim Verallgemeinern auf 3D aufpassen. Schließlich konnten wir für 2D die konvexe Hülle als Sequenz von Punkten repräsentieren. Für höhere Dimensionen müssen wir sie allerdings als Menge von Facetten repräsentieren. Glücklicherweise tauchen für noch höhere Dimensionen dann keine weiteren Schwierigkeiten mehr auf — abgesehen von der Grundsätzlichen Schwierigkeit, dass höherdimensionale Gebilde deutlich größere Oberflächen haben und somit die konvexe Hülle aus deutlich mehr Facetten besteht, sodass die untere Schranke für die Komplexität für Dimension $d$ durch $\\mathcal{O}(n&#94;{\\lfloor d / 2 \\rfloor})$ gegeben ist. Bevor ich hier QuickHull für $d=3$ beschreibe, möchte ich darauf hinweisen, dass es die qhull Implementierung gibt, die sich bspw. auch um die subtilen numerischen Fehler kümmert, die sich bei sehr spitzen Winkeln einschleichen können. Grundsätzlich bleibt das Vorgehen gleich: Wir starten mit einem $d$-dimensionalen Simplex, also für $d=3$ mit einem Tetraeder, dessen Eckpunkte zur konvexen Hülle gehören. Dann führen wir für jede Facette den rekursiven Schritt durch: Finde den Punkt, der am weitesten vor der Facette (also außerhalb des Tetraeders) ist. Diesen Punkt nennt man Eye-Point . Denn es reicht jetzt im Gegensatz zum 2D Fall nicht mehr einfach neue Facetten aus den Rändern und dem neuen Punkt zu bilden. Stattdessen müssen wir alle Facetten, deren Vorderseite (also Außenseite) wir vom Eye-Point aus sehen können entfernen und neue Facetten mit dem Horizont und dem Eye-Point bilden. In der Animation unten sind der Eye-Point sowie die Facetten, die er sieht, rot dargestellt. Der Horizont ist mit schwarzen Strichen gekennzeichnet. Wird dieser Schritt rekursiv auf alle neu hinzugefügten Facetten angewendet, resultiert die konvexe Hülle. Und genauso, wenn auch deutlich schwieriger darstellbar, funktioniert es auch für alle höheren Dimensionen. Eine wichtige Anwendung für 3D konvexe Hüllen ist übrigens die Delaunay-Triangulation einer planaren Punktmenge. Die wiederum kann für eine effiziente Berechnung des Relative-Neighborhood-Graphs aus diesem Post genutzt werden.","tags":"Phys","url":"https://blog.schawe.me/paper-convex-highdim.html","loc":"https://blog.schawe.me/paper-convex-highdim.html"},{"title":"Perfect Snake","text":"Ich habe auf diesem Blog schon über eine Reihe von Snake Clonen [ 1 , 2 , 3 , 4 , 5 ] geschrieben, die zum Teil auch Autopilot-Strategien hatten [ 6 , 7 ]. Die Autopiloten waren zwar meist interessant anzusehen — vor allem bei hohen Geschwindigkeiten — aber bei weitem nicht perfekt. Auch wenn der Titel etwas zu viel verspricht, schafft es dieser Autopilot (zumindest manchmal) perfekte Spiele zu spielen. Und falls dieses gif nicht überzeugt, kann man den Autopiloten online — dank TensorFlow.js — direkt im Browser ausprobieren auf snake.schawe.me . Aber was steckt dahinter? Neuronale Netze Wenn man nicht clever genug ist, eine direkte Lösung für ein Problem zu finden, kann man versuchen ein neuronales Netz auf die Lösung des Problems zu trainieren. Vor einigen Jahren hat ein Artikel , in dem ein neuronales Netz trainiert wurde alte Atari-Spiele zu spielen, für mediale Aufmerksamkeit gesorgt. Und die gleiche Idee des Reinforcement Learning werde ich hier (nicht als erster [ 8 , 9 ]) auf Snake anwenden. Die grundlegende Idee von Reinforcement Learning ist relativ einsichtig: Wir belohnen das Modell für gute Entscheidungen, sodass es lernt mehr gute Entscheidungen zu treffen. In unserem Fall werden gute Entscheidungen dadurch definiert, dass sie zu einer hohen Punktzahl, also Länge der Schlange am Spielende, führen. Glücklicherweise können wir auf die Literatur zurückgreifen, wie wir diese grundsätzliche Idee umsetzen können. Das Modell, für das ich mich entschieden habe, ist ein Actor-Critic Ansatz. Dabei nutze ich ein neuronales Netz, das als Input den aktuellen Zustand des Spielfeldes bekommt — wie genau dieser Zustand aussieht, diskutieren wir weiter unten. Dann geht es durch ein paar Schichten und endet in zwei \"Köpfen\". Einer ist der Actor , mit drei Output-Neuronen, die für \"nach links\", \"nach rechts\" und \"geradeaus weiter\" stehen. Der andere ist der Critic , der ein Output-Neuron hat, das abschätzt wie lang die Schlange, ausgehend von der aktuellen Situation, noch werden kann — also wie gut die aktuelle Situation ist. Das Training läuft dann so ab, dass ein ganzes Spiel gespielt wird, folgend den Vorschlägen des Actors mit etwas rauschen, um neue Strategien zu erkunden. Sobald es beendet ist, weil die Schlange sich oder eine Wand gebissen hat, wird der Critic mit allen Zuständen des Spielverlaufs darauf trainiert, Schätzungen abzugeben, die möglichst gut zu der tatsächlich erreichten Länge am Spielende passen. Außerdem wird der Actor darauf trainiert gute Entscheidungen zu treffen, indem zu den Zuständen des Spielverlaufs andere Entscheidungen getroffen werden und die Bewertung des Critic der resultierenden Situationen als Qualität der Entscheidung genutzt wird. Actor und Critic helfen sich also gegenseitig besser zu werden. Der gemeinsame Teil des neuronalen Netzes sollte im Idealfall nach genügend gespielten Spielen dabei ein \"Verständnis\" für Snake entwickeln. Genial! Technische Nebensächlichkeiten Meine Implementierung benutzt die Python Bibliotheken Keras und Tensorflow zum Training und multiJSnake als Environment . Wir steuern also einen Java-Prozess, um unser neuronales Netz in Python zu trainieren. Diese Entscheidung ist etwas unorthodox, aber bot Potential für einen Blogpost auf dem Blog meines Arbeitgebers . Wir können das Environment getrost als Black-Box betrachten, die dafür sorgt, dass die Regeln von Snake befolgt werden. Lokale Informationen Eine der wichtigsten Entscheidungen ist nun, wie der Input in das Modell aussieht. Die einfachste Variante, die sich auch gut zum Testen eignet, ist die lokale Information rund um den Kopf der Schlange: Drei Neuronen, die jeweils 1 oder 0 sind, wenn das Feld links, rechts und geradeaus vom Kopf belegt sind (und acht weitere für etwas mehr Weitsicht auf die Diagonalen und übernächste Felder vorne, rechts, links und diesmal auch zurück). Damit die Schlange auch das Futter finden kann, fügen wir noch 4 weitere Neuronen hinzu, die per 1 oder 0 anzeigen, ob das Futter in, rechts, links oder entgegengesetzt der Bewegungsrichtung der Schlange ist. Mit diesem Input füttern wir eine einzelne vollvernetzte Schicht, hinter der wir direkt die Actor und Critic Köpfe anschließen. Das reicht aus, damit die Schlange nach ein paar tausend Trainingsspielen zielstrebig auf das Futter zusteuert und sich selbst ausweicht. Allerdings reicht es noch nicht, um zu verhindern, dass sie sich selbst in Schlaufen fängt. Da war der Autopilot von rsnake besser. Globale Informationen Um der Schlange eine Chance zu geben zu erkennen, dass sie sich gerade selbst fängt, sollte man ihr erlauben das ganze Spielfeld zu sehen — schließlich sehen menschliche Spieler auch das ganze Spielfeld. Bei einem $10 \\times 10$ Spielfeld haben wir also schon mindestens 100 Input-Neuronen, sodass vollvernetzte Schichten zu sehr großen Modellen führen würden. Stattdessen bietet es sich bei solchen zweidimensionalen Daten an convolutional neuronale Netze zu nutzen. Um es unserer Schlange etwas einfacher zu machen, werden wir unser Spielfeld in drei Kanäle aufteilen: der Kopf: nur an der Position des Kopfes ist eine 1, der Rest ist 0 der Körper: die Positionen an denen sich der Körper befindet zeigen wie viele Zeitschritte der Körper noch an dieser Position sein wird das Futter: nur an der Position des Futters ist eine 1, der Rest ist 0 Dies ist auch kein unfairer Vorteil, schließlich sehen menschliche Spieler das Bild auch mit drei Farbkanälen. Und damit die Schlange nicht auch noch lernen muss was rechts und links bedeutet, geben wir dem Actor 4 Outputs, die für Norden, Osten, Süden und Westen stehen. Dieses Modell-Layout verdient es dann schon eher als Deep Learning bezeichnet zu werden. Weitere Modell-Parameter, können auf github.com/surt91/multiJSnake nachgeschlagen werden. Nach einigen zehntausend Trainingsspielen funktioniert dieses Modell dann tatsächlich gut genug, um regelmäßig perfekte Spiele auf einem $10 \\times 10$ Spielfeld zu erreichen. Aber da ich es nur auf $10 \\times 10$ Feldern trainiert habe, versagt es leider auf jeder anderen Größe.","tags":"Code","url":"https://blog.schawe.me/perfect-snake.html","loc":"https://blog.schawe.me/perfect-snake.html"},{"title":"multiJSnake","text":"Vor Kurzem habe ich ein Server-Client Snake in meine Liste von simplen Snake-Clonen [ 1 , 2 , 3 , 4 , 5 , 6 ] eingereiht. Wie ich in meinem Artikel \"RestfulSnake\" bereits angedeutet hatte, habe ich es um eine Multiplayer Komponente erweitert. Das grundlegende Design ist, dass der Server in festen Intervallen den nächsten Zeitschritt berechnet, den Spielzustand an alle Spieler schickt und auf Steuerkommandos von den Spielern lauscht. Dass der Server die gesamte Spiellogik verwaltet ist einerseits möglich, weil Snake einen relativ kleinen Zustand hat und nicht extrem empfindlich auf Latenzen reagiert. Außerdem können Spieler nicht (so einfach) schummeln, wenn der Spiel-Zustand auf dem Server berechnet wird. Hier sehen wir auch schon das erste Problem für die alte Kommunikation per http: Da der Server nicht von sich aus Nachrichten an die Clients schicken kann, müssten die Clients pollen, was zu einem ganzen Haufen an Problemen führen kann (Poll kurz vor dem Tick zum nächsten Zeitschritt, Last, uneinheitliche Antwortzeiten und Races bei schlechtem Netzwerk, …) Genau für diesen Zweck sind aber Websocket -Verbindungen wie geschaffen! Da SpringBoot vernünftige Mechanismen mitbringt, um Websockets zu handhaben, ist die Umstellung sogar vergleichsweise schmerzfrei . Das größte Problem ist nun, dass die meisten Leute \"Rest\" als synonym für \"json über http\" verstehen. Also muss ein neuer Name her — leider war \"multisnake\" auf Heroku schon belegt, sodass ich mit \"multiJSnake\" subtil darauf hinweise, dass Java und JavaScript das fundament bilden. Ausprobiert werden kann es auf multijsnake.herokuapp.com und weitere Spieler können durch einen Einladungslink in die eigene Session eingeladen werden. Die Quellen sind natürlich auf Github: github.com/surt91/multiJSnake .","tags":"Code","url":"https://blog.schawe.me/multijsnake.html","loc":"https://blog.schawe.me/multijsnake.html"},{"title":"RestfulSnake","text":"Vor wenigen Monaten hatte ich eine handvoll Bewerbungsgespräche. Von \"Programmieraufgaben\", die durch das Erkennen der Fibonacci-Sequenz gelöst wurden bis zu \"Wie viele Grashalme gibt es in deiner Heimatstadt?\" war alles dabei. Unter anderem auch \"Wir glauben, dass du noch nie Java angefasst hast, deshalb sollst du ein Programm in Java schreiben, über das wir nächste Woche reden können!\" Also bin ich jetzt Java-Experte. Und das bedeutet, dass es Zeit ist für eine weitere Snake-Version [ 1 , 2 , 3 , 4 , 5 ]. Um besonders professionell zu wirken, habe ich mich für eine Client-Server-Architektur entschieden. Steuerkommandos werden per http post zum Server geschickt und in der Antwort steht die neue Position der Schlange. Das Backend nutzt Spring Boot und läuft auf einem Tomcat Server. Das Frontend besteht hauptsächlich aus dem Visualisierungs-Code von jsnake , aber echte Nerds werden es natürlich bevorzugen per curl zu spielen. Normalerweise würde man es natürlich mittels Kubernetes und Docker auf AWS laufen lassen, aber stattdessen habe ich mich dafür entschieden Heroku zu nutzen, um ein kleines Unternehmen zu unterstützen. Auf multijsnake.herokuapp.com kann man also eine Partie spielen. Und die Quellen liegen wie immer auf GitHub Überraschenderweise funktioniert das tatsächlich erstaunlich gut — solange die Latenz unter ~150 ms bleibt. Und dieses Design schreit geradezu nach einen Multiplayer-Modus…","tags":"Code","url":"https://blog.schawe.me/restfulsnake.html","loc":"https://blog.schawe.me/restfulsnake.html"},{"title":"Fira Code","text":"Fira ist eine humanist Sans-Serif Schriftart, die für FirefoxOS entwickelt wurde, und wird zur Zeit für die Sans-Serif Typen, wie die Überschriften, in diesem Blog genutzt. Aber eigentlich geht es mir hier um Fira Mono die dicktengleiche Variante, die später mit Ligaturen (und mehr) zu Fira Code erweitert wurde. Ich sehe wie in genau diesem Moment im Geist des Lesers die Frage \"Ligaturen in einer dicktengleichen Schrift?!\" auftaucht. Beziehungsweise \"Ist da ein Tippfehler in dickengleich ?\" oder \"Was sind Ligaturen?\" falls der Leser kein Hobby-Typographie-Nerd ist. Für letztere klären wir erstmal kurz die beiden Fragen: Die Dickte bezeichnet die Breite der Metall-Lettern im klassischen Buchdruck; wenn sie für alle Glyphen gleich ist, stehen die Buchstaben immer in perfekt ausgerichteten Spalten untereinander, was von vielen für das Schreiben von Code bevorzugt wird. Die meisten Schreibmaschinen haben ebenfalls solche Schrifttypen verwendet. Ligaturen sind Kontraktionen von mehreren Glyphen in eine Glyphe. Die typischen Ligaturen sind fi oder fl (allerdings nicht in der Schriftart, in der diese Zeilen geschrieben sind, weshalb ich hier ein Bild der fi Ligatur in Computer Modern zeige). Ein paar Ligaturen haben sich mittlerweile zu eigenen Symbolen entwickelt, wie das Kaufmannsund &, das ursprünglich eine Ligatur von et war (Latein für und ). Aber dieses Konzept beißt sich anscheinend mit einer dicktengleichen Schrift, in der jeder Buchstabe die gleiche Breite haben soll. Der Clou an der Sache ist, dass Fira Code Ligaturen für übliche Ausdrücke für mathematische Symbole in Programmiersprachen wie >=, != und -> hat, die wie folgt dargestellt werden: >=, !=, -> . Nur zu, kopiert diese Symbole in einen Editor eurer Wahl, um zu sehen, wie sie sich wieder in ihre Bestandteile zerlegen Nur eine Spielerei? Möglicherweise. Aber ich bin begeistert davon, und verwende Fira Code in allen Editoren, die Ligaturen unterstützen. Der Fairness halber sollte gesagt werden, dass Fira Code nicht als erstes Projekt diese Idee hatte. Hasklig beispielsweise hatte ihr erstes Release 2 Jahre vor der Veröffentlichung von Fira Code im Jahr 2014. Und mittlerweile sind Code-Ligaturen so ziemlich im Mainstream angekommen, seitdem JetBrains Mono im letzten Jahr von dem gleichnamigen IDE -Entwickler veröffentlicht wurde. Zum Schluss möchte ich noch auf eine Kleinigkeit aufmerksam machen, die wohl nur die wenigsten Nutzer von Fira Code bewusst bemerken würden, die aber zweifellos demonstriert wie durchdacht diese Schrift ist. Denn Fira Code passt die Position von arithmetischen Symbolen an die benachbarten Glyphen an: ein + zwischen zwei Großbuchstaben ist höher als eines zwischen zwei Kleinbuchstaben. Ich persönlich weiß solche Details sehr wertzuschätzen. Es ist ein Beispiel dafür, dass alle Aspekte unserer modernen Gesellschaft, so wenige Gedanken wir uns auch darum machen und für wie trivial wir sie halten, zahllose Stunden Design und Entwicklung gekostet haben und ständig verbessert werden. Typographie — und um das klarzustellen, ich bin beileibe kein Experte — fasziniert mich. Schriften sind exakt, mit klar definierter Funktion, aber obwohl wir sie seit Jahrtausenden benutzen, ist ihre Entwicklung noch lange nicht abgeschlossen. Mit jedem neuen Medium gibt es neue Anforderungen. Marken haben steten Bedarf an individuellen Schrifttypen als Teil ihres Brandings. Für jede neue Anwendung gibt es andere Optimierungskriterien. Und jedes Mal wenn in meinem Code = und > wieder zu => verschmelzen, freue ich mich erneut über die Magie.","tags":"Meta","url":"https://blog.schawe.me/fira.html","loc":"https://blog.schawe.me/fira.html"},{"title":"Noch mehr Fraktale","text":"Seit meinem ersten Eintrag über meinen Fraktal-tweetenden Bot @AFractalADay , habe ich selbigen noch um ein paar Fraktale erweitert, die ich hier kurz festhalten möchte. Der ganze Code ist auf Github . Chaotic Maps Eine Quadratic Map ist eine Rekursionsgleichung mit einem quadratischen Term, also beispielsweise $$x_{i+1} = a_0 x&#94;2 + a_1 x + a_2.$$ Das berühmteste Mitglied dieser Familie ist die Logistic-Map mit $a_0=1, a_1=r, a_2=0$, die chaotisches Verhalten für $3.56995 < r < 4$ zeigt. Aber leider ist sie nur eindimensional und ihr Attraktor deshalb nicht besonders hübsch. Um visuell ansprechende Fraktale daraus zu erzeugen, brauchen wir also ein System aus zwei Rekursionsgleichungen, die wir als $x$- und $y$-Koordinaten betrachten können: \\begin{align } x_{i+1} &= a_{0} + a_{1} x + a_{2} x&#94;2 + a_{3} x y + a_{4} y + a_{5} y&#94;2\\ y_{i+1} &= a_{6} + a_{7} x + a_{8} x&#94;2 + a_{9} x y + a_{10} y + a_{11} y&#94;2. \\end{align } Jetzt haben wir 12 freie Parameter, die einen riesigen Parameterraum aufspannen, in dem etwa 1.6% aller Möglichkeiten chaotisches Verhalten mit einem seltsamen Attraktor zeigen. Chaotische Differentialgleichungssysteme Ein echter Klassiker ist das Differentialgleichungssystem, das die Chaostheorie begründet hat und nach dem der Schmetterlingseffekt benannt ist [ 1 , 2 ]. Für bestimmte Paramtersätze verlaufen die Bahnkurven entlang eines seltsamen Attraktors , dessen fraktale Dimension $\\approx 2.06$ ist. Da der vollständige Attraktor somit in einer zweidimensionalen Projektion etwas langweilig aussieht, habe ich hier nur eine Trajektorie über kurze Zeit dargestellt. Und es gibt eine ganze Menge weitere Differntialgleichungssysteme (und chaotic maps ), die chaotische Attraktoren aufweisen. Deshalb zeige ich hier noch einen Rössler-Attraktor, der eine vereinfachte Version des Lorenz-Systems ist: \\begin{align } \\frac{\\mathrm{d}x}{\\mathrm{d}t} &= -(y+z)\\ \\frac{\\mathrm{d}y}{\\mathrm{d}t} &= x + ay\\ \\frac{\\mathrm{d}z}{\\mathrm{d}t} &= b + xz - cz \\end{align } Und hier haben wir das Glück, dass auch seine Projektion sehr ansehnlich ist. Ich persönlich frage mich, nun wie der Attraktor für das Doppelpendel aussieht. Es ist anscheinend kein Fraktal, aber es sieht dennoch ganz interessant aus: Ising model Das Ising Modell für Ferromagnetismus wird auch als Drosophila der statistischen Physik bezeichnet: Es ist ein einfaches Modell, dass einen Phasenübergang aufweist — Eisen verliert seine magnetischen Eigenschaften oberhalb der Curie-Temperatur. Es besteht aus magnetischen Momenten, Spins , die gerne in die gleiche Richtung zeigen wie ihre Nachbarn, aber durch hohe Temperatur gestört werden. Oder etwas formaler: Die innere Energie $U$ wird durch den Hamiltonian $\\mathcal{H} = - \\sum_{ } s_i s_j$ bestimmt, wobei $s_i = \\pm 1$, je nachdem ob der Spin up oder down ist und die Summe über benachbarte Spins läuft. Das System wird immer einen Zustand anstreben, der die freie Energie $F=U- TS $ minimiert. Das kann entweder passieren, indem $U$ möglichst klein ist oder die Entropie $S$ möglichst hoch. Bei großen Werten der Temperatur $T$ bekommt der Entropie-Term ein höheres Gewicht, sodass Zustände mit hoher Entropie, also zufälligen Spinausrichtungen, bevorzugt sind, bei niedrigen Temperaturen werden Konfigurationen mit niedriger innerer Energie bevorzugt, also solche in denen alle Spins in die selbe Richtung zeigen. Die Temperatur, bei der sich beide Terme die Waage halten, nennt man kritische Temperatur. Hier bilden sich Regionen von Spins, die in die gleiche Richtung zeigen, auf allen Größenskalen. Die fraktale Dimension dieser Regionen ist 187/96 , was solche kritische Konfigurationen interessant anzusehen macht. Ich empfehle auf das folgende Bild zu klicken und etwas hineinzuzoomen.","tags":"Code","url":"https://blog.schawe.me/more-fractals.html","loc":"https://blog.schawe.me/more-fractals.html"},{"title":"Willkommen auf meinem Blog!","text":"Hier veröffentliche ich unregelmäßig Artikel über Dinge, mit denen ich mich beschäftige, oder die ich so nützlich finde, dass ich sie später nachschlagen will. Neuen Besuchern möchte ich eine handvoll Beiträge empfehlen, anstatt chronologisch herunterzuscrollen: A Fractal A Day zeigt hübsche Fraktale meines Twitter Bots @AFractalADay . Number of longest increasing subsequences stellt eine akademische Veröffentlichung, an der ich beteiligt war, und ihren zentralen Algorithmus vor. Perfect Snake präsentiert eine meiner Implementierungen des Spiels \"snake\" mitsamt einem neuronalen Netz als Autopilot.","tags":"Meta","url":"https://blog.schawe.me/welcome.html","loc":"https://blog.schawe.me/welcome.html"},{"title":"Twitter Profilhintergrundfarben","text":"Für ein Projekt habe ich Tweets von >8‘000‘000 Twitter-Usern eingesammelt. Dabei fallen noch eine Reihe weiterer Daten an, wie die Profilhintergrundfarbe. Es wäre eine Schande diese Daten einfach verkommen zu lassen, also habe ich nach einer Möglichkeit gesucht diese Information ansprechend darzustellen, was sich als weniger trivial herausgestellt hat, als ich ursprünglich angenommen hatte: Im Idealfall sollten ähnliche Farben nahe beieinander liegen, allerdings ist der RGB Farbraum ein dreidimensionaler Kubus, ein Bild aber nur zweidimensional, sodass es keine \"richtige\" Art und Weise gibt, ähnliche Farben nebeneinander anzuordnen. Ich habe mich hier dafür entschieden eine 2D Hilbert-Kurve durch mein Bild zu legen und die Farben in der Reihenfolge zu zeichnen, in der eine 3D Hilbert-Kurve ihnen im RGB -Kubus begegnet. Wenn man dann noch die beiden Standardhintergrundfarben #F5F8FA und #C0DEED ignoriert, sieht das Ergebnis so aus. Und dank der Python Pakete hilbertcurve und pypng ist der Code sogar ziemlich harmlos: from math import ceil , sqrt , log2 from hilbertcurve.hilbertcurve import HilbertCurve import png \"\"\" turn an RGB string like `#C0DEED` into a tuple of integers, i.e., coordinates of the RGB cube \"\"\" def str2rgb ( s ): s = s . strip ( \"#\" ) return ( int ( s [ 0 : 2 ], 16 ), int ( s [ 2 : 4 ], 16 ), int ( s [ 4 : 6 ], 16 )) \"\"\" `color_histogram` is a dict mapping an rgb string like `#F5F8FA` to the number of usages of this color \"\"\" def plot_background_colors ( color_histogram , filename = \"colors.png\" ): defaults = { \"F5F8FA\" , \"C0DEED\" } data = { str2rgb ( rgb ): d for rgb , d in color_histogram if rgb not in defaults } # calculate the size of the resulting image # for a 2D Hilbert curve, it mus be square with a width, which is a power of 2 num_pixels = sum ( data . values ()) min_width = ceil ( sqrt ( num_pixels )) exponent = ceil ( log2 ( min_width )) width = 2 ** exponent # output buffer for a width x width png, with 4 color values per pixel buf = [[ 0 for _ in range ( 4 * width )] for _ in range ( width )] hc2 = HilbertCurve ( exponent , 2 ) # there are 256 = 2&#94;8 values in each direction of the RGB cube hc3 = HilbertCurve ( 8 , 3 ) sorted_rgbs = sorted ( data . keys (), key = lambda x : hc3 . distance_from_point ( x )) idx = 0 for rgb in sorted_rgbs : for _ in range ( data [ rgb ]): # get the coordinate of the next pixel x , y = hc2 . point_from_distance ( idx ) # assign the RGBA values to the pixel buf [ x ][ 4 * y ] = rgb [ 0 ] buf [ x ][ 4 * y + 1 ] = rgb [ 1 ] buf [ x ][ 4 * y + 2 ] = rgb [ 2 ] buf [ x ][ 4 * y + 3 ] = 255 idx += 1 png . from_array ( buf , 'RGBA' ) . save ( filename ) Das Histogram, das als Input benötigt wird war in meinem Fall nur eine SQL Query entfernt: SELECT profile_background_color , COUNT ( profile_background_color ) FROM users GROUP BY profile_background_color ;","tags":"Code","url":"https://blog.schawe.me/twitter-background.html","loc":"https://blog.schawe.me/twitter-background.html"},{"title":"Raspberry Router","text":"Für die Fälle, in denen man nur per WLAN einen Zugang zum Internet und nur einen Raspberry PI dabei hat, aber dennoch kabelgebundenes Internet braucht, notiere ich diesen Eintrag. Für weitergehende Informationen ist das Arch Linux Wiki , wie immer, empfehlenswert. Wir müssen unseren Raspberry nur mit dem WLAN verbinden, das Ethernetkabel einstecken und spezifizieren, dass der Traffic vom einen zum anderen weitergeleitet werden sollen. sysctl net.ipv4.ip_forward = 1 iptables -t nat -A POSTROUTING -o wlan0 -j MASQUERADE iptables -A FORWARD -i wlan0 -o eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT iptables -A FORWARD -i eth0 -o wlan0 -j ACCEPT Da unser Raspberry jetzt ein Router ist, muss er natürlich auch die üblichen Aufgaben eines Routers übernehmen und die Geräte, die per Ethernet verbunden werden per DHCP mit IP Adressen versorgen, beispielsweise mittels dnsmasq mit folgender Konfiguration in /etc/dnsmasq.conf : #disable dns port=0 dhcp-range=192.168.13.50,192.168.13.150,12h bind-interfaces dhcp-option=3,0.0.0.0 dhcp-option=6,1.1.1.1,8.8.8.8 Bei der Gelegenheit kann man auch dafür sorgen, dass sämtlicher Traffic durch ein VPN geleitet wird, indem man das wlan0 Interface oben durch das konfigurierte VPN -Interface austauscht (zB. durch tun0 für OpenVPN oder wg0 für WireGuard).","tags":"Snip","url":"https://blog.schawe.me/raspberry-router.html","loc":"https://blog.schawe.me/raspberry-router.html"},{"title":"inline-python","text":"Für jeden Zweck das passende Werkzeug: In meinem Alltag bedeutet das, dass ich Simulationen in Rust schreibe und in Python visualisiere. Dank inline-python geht das sogar sehr reibungslos. use inline_python :: python ; fn main () { let x : Vec < f32 > = ( 0 .. 628 ). map ( | i | i as f32 / 100. ). collect (); let y : Vec < f32 > = x . iter (). map ( | x | x . sin ()). collect (); python ! { import numpy as np from matplotlib import pyplot as plt plt . plot ( ' x , ' y ) plt . show () } } Dieses Minimalbeispiel ist natürlich nicht nützlich, aber ich habe es bereits produktiv genutzt, um Dynamik auf petgraph Graphen zu simulieren und ihren Zustand per graph-tool zu visualisieren.","tags":"Code","url":"https://blog.schawe.me/inline-python.html","loc":"https://blog.schawe.me/inline-python.html"},{"title":"Number of longest increasing subsequences","text":"Meine liebsten Probleme sind solche, die einfach scheinen aber sehr tief sind. Natürlich gehört das Problem des Handlungsreisenden dazu: Es ist einfach zu verstehen, dass der Müllmann bei jeder Mülltonne vorbei muss und dabei möglichst wenig Strecke fahren will. Gerade deshalb ist es das Paradebeispiel für NP -schwere Probleme (technisch gesehen ist nur seine Entscheidungs-Version \"Gibt es eine Tour, die kürzer ist als $X$\" NP -schwer und nicht die typische Optimierungsversion: \"Welche ist die kürzeste Tour\"). Aber fast noch besser gefällt mir das Problem der längsten aufsteigenden Teilfolge , oder auf englisch, longest increasing subsequence ( LIS ): Gegeben eine Folge von Zahlen $S_i$, welche Teilfolge ist am längsten unter der Bedingung, dass die Zahlen aufsteigen. Dieses Problem ist so einfach, dass es erstmals von Stanisław Ulam als Fingerübung beschrieben wurde und nach meinem Eindruck heutzutage als Übung für dynamische Programmierung in Universitäten verwendet wird. Wer weiß wie viele Bewerber vor einem Whiteboard ins Schwitzen geraten sind bei dem Versuch es aus dem Stegreif zu lösen. Auf der anderen Seite ist es aber offenbar tief genug, dass man ganze Bücher darüber schreiben kann. Es zeigen sich überraschende Querverbindungen zu scheinbar unabhängigen Problemen. Denn die Länge $L$ der LIS einer Permutation fluktuiert genauso wie der Abstand von der Mitte zum Rand eines Kaffeeflecks oder die größten Eigenwerte von Zufallsmatrizen . Nun ist die Lösung dieses Problems nicht eindeutig: Es kann viele längste aufsteigende Teilfolgen geben. Tatsächlich wächst die Anzahl sogar exponentiell mit der Länge der ursprünglichen Sequenz. Allerdings wurde bisher nie untersucht wie viele genau. Oftmals hört man, es sei nicht praktikabel alle durchzuzählen, da es exponentiell viele seien. Und wenn es darum ginge alle zu enumerieren, würde das stimmen. Aber wir wollen an dieser Stelle nur die Anzahl wissen, die wir mittels dynamischer Programmierung effizient bestimmen können. Die Idee ist, dass wir für jedes Element, das an Position $x$ in einer LIS auftauchen kann, berechnen, wie viele aufsteigende Teilfolgen der Länge $L-x$ mit diesem Element beginnen. Besonders einfach geht das, wenn wir zuerst eine Datenstruktur aufbauen, die kodiert welche Elemente in einer LIS aufeinander folgen können. Dazu erweitern wir Patience Sort , und da dieser Algorithmus nach einem Kartenspiel benannt ist, werden wir es auch mit Karten visualisieren: Wir schreiben jedes Element unserer Sequenz auf eine Karte und legen die Karten auf einen Stapel, sodass das erste Element der Sequenz oben liegt. Dann nehmen wir Karten von oben ab und legen sie auf verschiedene Stapel. Die erste Karte legen wir auf den ersten, noch leeren Stapel. Die folgenden Karten legen wir auf den ersten Stapel, dessen oberstes Element größer ist als die aktuelle Karte und ansonsten machen wir einen neuen Stapel rechts davon auf. Jedes mal wenn wir eine Karte ablegen, lassen wir sie auf alle Karten, die aktuell auf dem Vorgängerstapel liegen und kleiner sind, zeigen — dies sind die Karten die in einer aufsteigenden längsten Teilfolge direkt vor ihr auftauchen können. Am Ende haben wir $L$ Stapel, wobei $L$ die Länge der LIS ist, und wir können vom Stapel ganz rechts starten und den Pfeilen folgen, um eine LIS zusammenzubauen. Wenn wir nur an der Länge interessiert wären , müssten wir uns über den Inhalt der Stapel keine Gedanken machen und der Algorithmus ließe sich sehr kompakt darstellen: fn lis_len < T : Ord > ( seq : & [ T ]) -> usize { let mut stacks = Vec :: new (); for i in seq { let pos = stacks . binary_search ( & i ) . err () . expect ( \"Encountered non-unique element in sequence!\" ); if pos == stacks . len () { stacks . push ( i ); } else { stacks [ pos ] = i ; } } stacks . len () } Aber wir wollen mehr, deshalb notieren wir uns im nächsten Schritt bei allen Karten des rechtesten Stapels wie viele aufsteigende Teilfolgen der Länge $x=1$ mit ihnen starten, was trivialerweise je eine ist. Dann notieren wir bei allen Karten des Stapels links davon wie viele aufsteigenden Teilfolgen der Länge 2 mit ihnen anfangen. Das können wir berechnen, indem wir den Pfeilen rückwärts folgen und die Annotationen jeweils aufaddieren. Nachdem wir dies für alle Stapel wiederholt haben und den linkesten Stapel beschriftet haben, können wir alle Annotationen des linkesten Stapels aufaddieren, um die gesamte Anzahl LIS zu erhalten: hier $7$. Wie sich das ganze für längere Sequenzen aus unterschiedlichen Zufallsensembles im Detail verhält haben wir in einem Artikel veröffentlicht.","tags":"Phys","url":"https://blog.schawe.me/paper-lis2.html","loc":"https://blog.schawe.me/paper-lis2.html"},{"title":"compress-pdf","text":"Um ein pdf mit vielen zu hoch aufgelösten Bildern auf eine angemessene Dateigröße zu bringen (durch das Herunterskalieren und gegebenenfalls Neukodieren der Bilder), kann einfach ghostscript genutzt werden: gs -sDEVICE = pdfwrite -dCompatibilityLevel = 1 .4 -dPDFSETTINGS = /ebook -dEmbedAllFonts = true -dSubsetFonts = true -dNOPAUSE -dQUIET -dBATCH -sOutputFile = output.pdf input.pdf Die Qualitätspresets sind screen , ebook , printer , prepress und default . Weitere Optionsnamen können durch folgendes Kommando ermittelt werden: gs -sDEVICE = pdfwrite -o /dev/null -c \"currentpagedevice { exch ==only ( ) print == } forall\"","tags":"Snip","url":"https://blog.schawe.me/compress-pdf.html","loc":"https://blog.schawe.me/compress-pdf.html"},{"title":"smartphone webcam","text":"Um die Kamera eines Smartphones als Webcam für eine Videokonferenz auf dem Computer zu nutzen, braucht man zuerst eine App, die das Bild der Kamera als http -Stream bereit stellt, bspw. IP Webcam . Für Linux existieren die Projekte v4l2loopback und ffmpeg mit deren Hilfe der Stream als Webcam input genutzt werden kann (hier für den Fall, dass das Smartphone die IP 192.168.1.127 hat): sudo modprobe v4l2loopback ffmpeg -i http://192.168.1.127:8080/video -map 0 :v -vcodec rawvideo -vf format = yuv420p -fflags nobuffer -flags low_delay -fflags discardcorrupt -f v4l2 /dev/video2 Natürlich kann man beliebige Filter von ffmpeg anwenden, zum Beispiel einen colorkey oder chromakey , um ein beliebiges Bild background.jpg als virtuellen Hintergrund zu nutzen. Hier für den Fall, dass ein weißes Bettlaken als \"green screen\" genutzt wird: ffmpeg -i images/background.jpg -i http://192.168.1.127:8080/video -vcodec rawvideo -fflags nobuffer -flags low_delay -fflags discardcorrupt -filter_complex \"[1:v]colorkey=0xbbbbbb:0.3:0.2[foregroud];[0:v][foregroud]overlay[composite];[composite]format=yuv420p[out]\" -map \"[out]:v\" -f v4l2 /dev/video2 Ähnlich kann auch das Smartphone-Mikrophon als Mikrophon für den Computer genutzt werden. Hier mithilfe von pulseaudio und gstreamer : pactl load-module module-null-sink sink_name = \"ipwebcam\" pactl set-default-source \"ipwebcam.monitor\" gst-launch-1.0 souphttpsrc location = \"http://192.168.1.127:8080/audio.wav\" is-live = true ! audio/x-raw,format = S16LE,layout = interleaved,rate = 44100 ,channels = 1 ! queue ! pulsesink device = \"ipwebcam\"","tags":"Snip","url":"https://blog.schawe.me/smartphone-webcam.html","loc":"https://blog.schawe.me/smartphone-webcam.html"},{"title":"Phase Transitions of Traveling Salesperson Problems solved with Linear Programming and Cutting Planes","text":"In diesem Artikel wird ein Ensemble von Problemen des Handlungsreisenden ( TSP ) eingeführt, das abhängig von einem Parameter $\\sigma$ von einer trivial einfach zu lösenden Konfiguration, nämlich Städte, die äquidistant auf einem Kreis angeordnet sind, zum zufälligen euklidischen TSP in der Ebene interpoliert. Danach werden mittels linearer Programmierung einige Phasenübergänge festgestellt, ab welchen Werten von $\\sigma$ das Problem schwierig zu lösen wird. Zu zwei dieser Übergänge werden strukturelle Eigenschaften der optimalen Lösung gefunden, die sich an dieser Stelle ebenfalls charakteristisch ändern. Da die optimale Lösung nicht von der Lösungsmethode abhängt, sind diese Phasenübergänge also nicht nur von Bedeutung für das spezielle Lineare Programm bzw. den Algorithmus der zu dessen Lösung genutzt wurde, sondern fundamentale Eigenschaft dieses TSP Ensembles. Im Detail haben wir die klassische Formulierung von Dantzig genutzt: \\begin{align } \\label{eq:objective} &\\text{minimize} & \\sum_i \\sum_{j<i} c_{ij} x_{ij}\\ \\label{eq:int} &\\text{subject to} & x_{ij} &\\in {0,1}\\ %\\mathbb{Z}\\ \\label{eq:inout} & & \\sum_{j} x_{ij} &= 2& & \\forall i \\in V \\ \\label{eq:sec} & & \\sum_{i \\in S, j \\notin S} x_{ij} &\\ge 2& & \\forall S \\varsubsetneq V, S \\ne \\varnothing \\end{align } Hier ist $c_{ij}$ die Distanzmatrix zwischen allen Paaren von Städten aus $V$ und $x_{ij}$ die gesuchte Adjazenzmatrix, also $x_{ij} = 1$, wenn $i$ und $j$ aufeinanderfolgende Stationen der Tour sind und $x_{ij} = 0$ sonst. Die erste Zeile minimiert also die Strecke der Tour. Um zu vermeiden, dass wir die triviale Lösung $x_{ij}=0$, also \"wenn wir zu Hause bleiben müssen wir am wenigsten Strecke zurücklegen\" finden, zwingt die dritte Zeile unseren Handlungsreisenden seine Tour so zu planen, dass in Summe zwei Striche an jede Stadt gezeichnet werden — genug, um hinein und wieder hinaus zu reisen. Allerdings, ist unser Handlungsreisender clever und würde versuchen uns auszutricksen, indem er halbe Striche einzeichnen würde, wie in einem anderen Blogeintrag visualisiert . Deshalb ist die Bedingung in der zweiten Zeile nötig, die die Einträge in der Adjazenzmatrix auf ganze Zahlen beschränkt. Dann bleibt nur noch das Problem, dass mehrere Routen, die nicht verbunden sind erlaubt wären, sodass wir sie durch die letzte Zeile verbieten: die Subtour Elimination Constraints . Der aufmerksame Leser mag schon erkannt haben, dass es für jede Untermenge von Städten so eine Constraint definiert, also exponentiell viele in der Anzahl der Städte. Die Lösung zu dieses Problem liegt darin, dass nur sehr wenige wirklich gebraucht werden, sodass man das Problem ohne diese Constraint löst, testet ob eine verletzt ist, was mittels der Berechnung eines minimum cut sehr schnell geht und dann eine einzelne Constraint, die diese Konfiguration verbietet hinzufügt. Diese Methode iterativ Constraints hinzuzufügen wird meist als Cutting Planes bezeichnet. Also haben wir einen schnellen Algorithmus für das Problem des Handlungsreisenden gefunden? Nein, leider können wir den Millenium Preis noch nicht beanspruchen. Es gibt keinen bekannten Algorithmus, der dieses Problem unter Erfüllung der zweiten Zeilen, also Beschränkung auf ganzzahlige Lösungen lösen kann. Aber sobald wir diese Bedingung fallen lassen, können wir klassische Verfahren der linearen Programmierung nutzen, um dieses Problem effizient zu lösen. Dies wird auch Relaxation genannt. Die Länge der Strecke ist immer eine untere Schranke für die tatsächliche Lösung. Und wenn unsere Lösung per Zufall ganzzahlig ist, können wir uns sicher sein, die Optimale Lösung gefunden zu haben. Als Ordnungsparameter des Phasenübergangs zwischen leichten und schweren Konfigurationen dient uns also die Wahrscheinlichkeit, dass mittels eines Simplex-Solvers eine ganzzahlige, und damit optimale, Lösung gefunden wird. Ohne die Subtour Elimination Constraints, fällt der Phasenübergang auf den Punkt, an dem sich die optimale Lösung erstmals von der Reihenfolge der Städte des ursprünglichen Kreises unterscheidet. Mit den Subtour Elimination Constraints, fällt der Phasenübergang auf den Punkt, wo die optimale Tour anfängt von einem Zickzack-Kurs auf große Meander zu wechseln. Dies wird durch die geometrische Gewundenheit, die Tortuosität , \\begin{align } \\tau = \\frac{n-1}{L} \\sum_{i=1}&#94;{n} \\left( \\frac{L_i}{S_i}-1 \\right). \\end{align } ermittelt, die an diesem Punkt maximal wird. Hier wird die Tour in $N$ Teilstücke mit gleichem Vorzeichen der Krümmung unterteilt und für jedes Teilstück das Verhältnis von direkter Ende-zu-Ende-Distanz $S_i$ zu der Länge entlang der Tour $L-i$ summiert. Wir haben also kontinuierliche Phasenübergänge in der Schwierigkeit dieses Problems mittels linearer Programmierung detektiert und sie mit strukturellen Änderungen des Verhaltens in Verbindung gebracht.","tags":"Phys","url":"https://blog.schawe.me/paper-tsp-pt.html","loc":"https://blog.schawe.me/paper-tsp-pt.html"},{"title":"relay ssh","text":"Um sich per Server relay mit target zu verbinden. Nützlich wenn target hinter einer Firewall versteckt, aber von relay erreichbar ist. ssh -J user1@relay user2@target Dies kann mit anderen Optionen kombiniert werden, sodass eine Portweiterleitung stattfinden kann, über die bspw. sshfs genutzt werden kann. ssh -L 9999 :localhost:22 -J user1@relay user2@target sshfs user2@localhost:/path /mountpoint -C -p 9999 Eine Kombination mit reverse-ssh könnte so aussehen: ssh -L 9999 :localhost:22 -J user1@relay -p 19999 user2@localhost","tags":"Snip","url":"https://blog.schawe.me/relay-ssh.html","loc":"https://blog.schawe.me/relay-ssh.html"},{"title":"latexdiff","text":"Um die Unterschiede zwischen zwei Latex Dateien zu ermitteln, die beispielsweise aus Git kommen. latexdiff old.tex new.tex > diff.tex pdflatex diff.tex Und wenn man sowieso schon git benutzt, reicht es einfach den Hash des Commits angeben, den man mit dem aktuellen Stand vergleichen will. latexdiff-vc -r 96deadbeef filename.tex --pdf","tags":"Snip","url":"https://blog.schawe.me/latexdiff.html","loc":"https://blog.schawe.me/latexdiff.html"},{"title":"reverse ssh","text":"Führe auf dem Computer target , der hinter einer Firewall steht und dennoch per SSH erreichbar sein soll folgendes aus ssh -f -N -R 0 .0.0.0:19999:localhost:22 user@server server muss erreichbar sein und in /etc/ssh/sshd_config folgende Option aktiviert haben GatewayPorts yes Jetzt kann man von beliebigen Clients auf den Computer target zugreifen per ssh -p 19999 user@server So kann man beispielsweise auch sshfs nutzen. sshfs -p 19999 user@server:folder ~/sshfs","tags":"Snip","url":"https://blog.schawe.me/reverse-ssh.html","loc":"https://blog.schawe.me/reverse-ssh.html"},{"title":"Pebble Rules","text":"Im letzten Monat habe ich jemanden getroffen, auf dessen Armbanduhr eine MCMC Simulation von Hamilton-Pfaden auf einem quadratischen Gitter liefen. Ich war derartig begeistert, dass ich beschlossen habe auch etwas auf meiner Pebble simulieren zu lassen. Aufgrund der geringen Auflösung des Displays ($144 \\times 168$) bieten sich \"blockige\" Visualisierungen an. Glücklicherweise habe ich schon genügend Spielereien geschrieben, die sich eignen [ 1 , 2 , 3 , 4 ]. Pebble wurde zwar inzwischen von Fitbit aufgekauft, aber das SDK ist noch verfügbar. Die neueren Exemplare lassen sich per JavaScript programmieren, meine \"Kickstarter Edition\" aus der ersten Generation allerdings noch nicht. Da ich meine Uhr also in C programmieren muss, konnte ich allerdings den den alten Code aus Wolfram's Rules wiederbenutzen. Your browser does not support the video tag. Der Code ist auf GitHub verfügbar.","tags":"Code","url":"https://blog.schawe.me/pebble-rules.html","loc":"https://blog.schawe.me/pebble-rules.html"},{"title":"A Fractal A Day","text":"Vor einiger Zeit habe ich ein Programm geschrieben, das verschiedene Typen von Fraktalen generiert. Da viele Methoden Fraktale zu generieren relativ einfach zu parallelisieren sind und großen Bedarf an Rechenkraft haben, habe ich mich entschieden es in Rust zu implementieren. Bei Interesse kann das Programm von Github bezogen werden. Da Fraktale nett anzuschauen sind, ist dieser Beitrag voller hochaufgelöster Bilder. Damit diese Seite dennoch flüssig geladen wird — auch bei langsamen Verbindungen, habe ich extra für diesen Eintrag in die Technik dieses Blogs eingegriffen. Außerdem gibt es @AFractalADay auf Twitter, der täglich ein zufälliges Fraktal tweetet. Escape Time Die erste Klasse von Fraktalen, die ich hier zeigen möchte, wird definiert durch das Konvergenzverhalten des wiederholten Anwendens einer Funktion. Was genau dieser Satz bedeutet, lässt sich am besten an einem Beispiel erklären. Mandelbrot-Menge Das vermutlich bekannteste Fraktal ist das Apfelmännchen, das die Mandelbrotmenge visualisiert. Das ist die Menge der komplexen Zahlen $c = x + iy,$ die nicht konvergieren, wenn die Funktion $f_c(z) = z&#94;2 + c$ wiederholt angewendet wird. Also wenn die Folge $$f_c(0), f_c(f_c(0)), f_c(f_c(f_c(0))), …$$ gegen einen endlichen Wert strebt. Wenn man jeden Punkt $c$ auf der komplexen Ebene entsprechend des Konvergenzverhaltens bezüglich dieser Folge einfärbt — schwarz wenn es konvergiert, blau für langsame Divergenz, rot für schnelle Divergenz — erhält man ein solches Bild: Dies ist ein Zoom auf den Rand des Apfelmännchens. Tatsächlich ist die Mandelbrotmenge kein Fraktal im eigentlichen Sinne, da seine fraktale Dimension 2 ist — der schwarze Bereich füllt eine Fläche. Es einfach möglich dieses Fraktal zu rastern und dabei jeden Pixel parallel zu berechnen. Eine naive Implementierung könnte wie folgt aussehen. // convenient iterators #[macro_use] extern crate itertools ; use itertools :: Itertools ; // parallelism extern crate rayon ; use rayon :: prelude :: * ; // complex numbers extern crate num ; use num :: complex :: Complex ; fn raster ( resolution : ( u32 , u32 )) -> Vec < u64 > { let ( x , y ) = resolution ; // generate the points, we want to raster let pixels : Vec < ( u32 , u32 ) > = iproduct ! ( 0 .. y , 0 .. x ). collect (); // start a parallel iterator on the points ... pixels . par_iter () . map ( |& ( j , i ) | { // ... mapping every point ... let z = map_to_cplx_plane ( i , j ); // ... to the number of iterations needed to diverge time_to_diverge ( z ) }) . collect () } fn map_to_cplx_plane ( x : u32 , y u32 ) -> Complex < f64 > { // TODO: here we need to get the offset and scale somehow let x = ( x - x_offset ) as f64 * x_scale ; let y = ( y - y_offset ) as f64 * y_scale ; Complex < f64 > { re : x , im : y } } fn time_to_diverge ( mut state : Complex < f64 > ) -> u64 { // threshold is 2&#94;2, since we compare to the square of the norm // as soon as the norm is >= 2 it is sure to diverge let threshold = 4. ; // abort after 1000 iterations let max_count = 1000 ; let c = state ; let mut ctr = 0 u64 ; while { state = state * state + c ; ctr += 1 ; state . norm_sqr () < threshold && ctr < max_count } {} ctr } Julia-Mengen Nahe verwandt sind die Julia-Mengen. Hier benutzt man die gleiche Funktion $f_c$, allerdings färbt man jeden Punkt $z$ entsprechend seines Konvergenzverhaltens bei einem festen Parameter $c$. Tatsächlich ist jede beliebige Funktion $f$ erlaubt und nicht nur die oben erwähnte quadratische. Mit unkonventioneller Zuordnung von Farben zu Divergenzzeiten ergibt sich mit $f(z) = (-2.6-i) \\cosh(z)$ dieses Bild: Newton-Fraktal Das Newton-Verfahren zur Findung von Nullstellen startet an einem beliebigen Punkt auf einer Kurve, und berechnet die Nullstelle der Tangente an diesem Punkt. Mit der Tangente dieses Punktes wird genauso verfahren. Dabei sollten sich die so erhaltenen Punkte immer dichter einer Nullstelle nähern. Bei einer komplexen Funktion können wir dies für jeden Startpunkt iterieren. Jeder Punkt wird gegen eine Nullstelle konvergieren, der wir eine Farbe zuordnen und den Punkt mit dieser Farbe einfärben. Wenn wir die Sättigung davon abhängig machen, wie schnell die Konvergenz ist, sieht das Ergebnis für $f(x) = z&#94;4 + 5&#94;{z+i} + 15$ so aus. Chaos Game Eine große Klasse von Fraktalen lässt sich mit dem Chaos Game erzeugen. Man benutzt dazu mindestens zwei Abbildungen $f_1(z)$ und $f_2(z)$, die jeweils einen Punkt $z$ auf einen anderen Punkt abbilden. Man wählt einen Punkt zum Starten, bildet ihn mit einer Zufälligen der beiden Abbildungen ab, zeichnet den resultierenden Punkt ein und wiederholt dies sehr oft. Dieser Algorithmus ist inherent sequenziell, allerdings kann man parallel an vielen verschiedenen Punkten starten und die Ergebnisse dieser unabhängigen Markovketten in einem Bild zusammenführen. In Rust könnte der entsprechende Codeschnipsel so aussehen: extern crate num_cpus ; use std :: thread ; use std :: sync :: mpsc :: channel ; let cpus = num_cpus :: get (); // create a transmitter, receiver pair let ( tx , rx ) = channel (); for _ in 0 .. cpus { // clone a transmitter for each thread let tx = tx . clone (); // generator yielding the points from the chaos game // using a random seed let sampler = get_sampler (); // we need some histogram implementation let mut hist = Histogram :: new (); thread :: spawn ( move || { // feed the samples into the histogram hist . feed ( sampler . take ( iterations_per_task )); // send the finished histogram to the receiver tx . send ( hist ). unwrap (); }); } // collect all parallel computed histograms into main_hist let mut main_hist = Histogram :: new (); for _ in 0 .. cpus { let h = rx . recv (). unwrap (); main_hist . merge ( & h ); } Sierpinski-Dreieck und Barnsley-Farn Mit dieser Methode kann man alte Bekannte wie das Sierpinski-Dreieck erzeugen. Dazu benötigt man die drei affinen Transformationen, die man alle mit gleicher Wahrscheinlichkeit auswählt: $$\\begin{align} f_1(\\vec z) &=\\begin{pmatrix} -1/4 & \\sqrt 3 / 4 \\ -\\sqrt 3 / 4 & -1/4 \\end{pmatrix} \\cdot \\begin{pmatrix} z_x \\ z_y \\end{pmatrix} + \\begin{pmatrix} -1/4\\ \\sqrt 3 / 4 \\end{pmatrix}\\ f_2(\\vec z) &=\\begin{pmatrix} 1/2 & 0 \\ 0 & 1/2 \\end{pmatrix} \\cdot \\begin{pmatrix} z_x \\ z_y \\end{pmatrix} + \\begin{pmatrix} 1/4\\ \\sqrt 3 / 4 \\end{pmatrix}\\ f_3(\\vec z) &=\\begin{pmatrix} -1/4 & -\\sqrt 3 / 4 \\ \\sqrt 3 / 4 & 1/4 \\end{pmatrix} \\cdot \\begin{pmatrix} z_x \\ z_y \\end{pmatrix} + \\begin{pmatrix} 1\\ 0 \\end{pmatrix} \\end{align}$$ Ein anderes berühmtes Beispiel ist der Barnsley-Farn. Um ihn zu erzeugen, benutzt man die folgenden vier affinen Abbildungen, die man mit den Wahrscheinlichkeiten $$p_1 = 0.01, p_2 = 0.85, p_3 = 0.07, p_4 = 0.07$$ verwendet: $$\\begin{align} f_1(z) &=\\begin{pmatrix} 0.16\\ 0 \\end{pmatrix}\\ f_2(z) &=\\begin{pmatrix} 0.85 & 0.04 \\ 0 & -0.04 \\end{pmatrix} \\cdot \\begin{pmatrix} z_x \\ z_y \\end{pmatrix} + \\begin{pmatrix} 0.85\\ 1.6 \\end{pmatrix}\\ f_3(z) &=\\begin{pmatrix} 0.2 & -0.26 \\ 0 & 0.23 \\end{pmatrix} \\cdot \\begin{pmatrix} z_x \\ z_y \\end{pmatrix} + \\begin{pmatrix} 0.22\\ 1.6 \\end{pmatrix}\\ f_4(z) &=\\begin{pmatrix} -0.15 & 0.28 \\ 0 & 0.26 \\end{pmatrix} \\cdot \\begin{pmatrix} z_x \\ z_y \\end{pmatrix} + \\begin{pmatrix} 0.24\\ 0.44 \\end{pmatrix}\\ \\end{align}$$ Als Ergebnis erhält man diesen Farn. Fractal Flame Fractal Flame ist der Name einer Klasse von Zufallsfraktalen, die nach dem gleichen Muster wie oben aus einer Reihe affiner Transformationen $A_i$ bestehen. Zusätzlich können die affinen Transformationen mit einer nichtlinearen Variation $V_j$ erweitert werden, sodass $f_i(\\vec z) = V_j(A_i(\\vec z))$ (oder Linearkombinationen dieser Variationen). Zur Visualisierung werden die Punkte nicht direkt gezeichnet, sondern in ein Histogramm eingetragen, aus dem die Farbintensitäten typischerweise logarithmisch berechnet werden. Hier wird jedem $f_i$ ein Farbton zugeordnet. Die Farbe eines Punktes ist eine Mischung dieser Farben, die widerspiegelt, wie oft eine Abbildung genutzt wurde, um an diesen Punkt zu gelangen. Interessanterweise sind diese Systeme anscheinend sehr anfällig für schlechte Zufallszahlen, was sich in \"Löchern\" in den ansonsten glatten Flächen bemerkbar macht. Möbius Flame Diese Fraktale sind nahezu identisch zu den Fractal Flames, nur dass anstatt von affinen Transformationen Möbius Transformationen auf der komplexen Ebene genutzt werden. $$f_i(z) = \\frac{a_i z + b_i}{c_i z + d_i}$$ Wie findet man \"gute\" Parameter? Offenbar hat dieser Typ von Fraktal sehr viele freie Parameter. Um hübsche Resultate zu generieren, müssen sie angepasst werden. Tatsächlich gibt es mit electric sheep (ich hoffe stark, dass es eine Blade Runner Referenz ist) ein Crowdsourcing-Projekt, das mithilfe von evolutionären Algorithmen und dem Feedback von Menschen besonders ansehnliche Fraktale erzeugt. Für mein Programm habe ich eine simplere Methode genutzt. Damit man ein Fraktal gut sehen kann, sollte seine fraktale Dimension größer als 1 sein. Abschätzbar ist es relativ einfach über die Korrelations-Dimension . Dazu misst man die paarweisen Abstände von Punkten und misst den Exponenten ihrer kumulativen Verteilungsfunktion. Kombiniert mit einigen Heuristiken, die zu langgestreckte Fraktale verhindert, sind die Ergebnisse meist ansprechend Weitere Fraktale Es gibt natürlich viel mehr Typen von Fraktalen. Auch wenn @AFractalADay sie bisher nicht zeichnen kann, habe ich einige Bilder angefertigt, die ich hier auch gerne zeigen möchte. Diffusionsbegrenztes Wachstum Diffusionsbegrenztes Wachstum bildet das Wachstum von Kristallen in stark verdünnten Lösungen ab. Man startet mit einem Seed und lässt dann einzelne Teilchen diffundieren, bis sie auf dem Nachbarfeld eines Seeds landen, wo sie dann bleiben und Teil des Seeds werden. Dieser Prozess bildet verästelte Strukturen aus. Random Walks Einige Arten von Random Walks haben eine fraktale Dimension zwischen 1 und 2, was sie zu ansehnlichen Fraktalen machen sollte. Der Smart Kinetic Self Avoiding Walk, der in meinem rsnake die Strategie des Autopiloten ist, hat eine fraktale Dimension von $\\frac{7}{4}$. 100000 Schritte sehen so aus:","tags":"Code","url":"https://blog.schawe.me/randomFractals.html","loc":"https://blog.schawe.me/randomFractals.html"},{"title":"Platzhalterbilder","text":"Große Bilder können die Ladezeit von Webseiten dramatisch verschlechtern. Schlimmer als weiße Flächen ist das sprungartige Verschieben des Textes, wenn weiter oben gerade ein Bild fertig geladen wurde. Allerdings müssen Bilder bei immer weiter steigenden Pixeldichten der Anzeigegeräte auch immer hochaufgelöster werden und gleichzeitig über langsame 3G-Verbindungen geladen werden. Da der Eintrag über Fraktale einige recht große Bilder enthält, habe ich ein Pelican-Plugin geschrieben, das Vorschau-.jpg erzeugt, die in der Regel kleiner als 1 kB sind, jedes Bild durch die data-uri des Previews ersetzt und dies verschwommen anzeigt, bis das Originalbild per JavaScript nachgeladen ist. Das sieht dann etwa so aus: Your browser does not support the video tag. Glücklicherweise ist es recht einfach mit Python html zu parsen und data-uri zu erzeugen, sodass mein Plugin im Wesentlichen fertig generiertes html nimmt und folgendes tut: import base64 from bs4 import BeautifulSoup with open ( \"file.html\" ) as f : soup = BeautifulSoup ( f , \"html.parser\" ) for img in soup . find_all ( \"img\" ): thumbnail = create_thumbnail ( img ) b64 = base64 . b64encode ( open ( thumbnail , \"rb\" ) . read ()) . decode ( \"utf-8\" ) data_uri = f \"data:image/jpeg;base64, { b64 } \" # TODO: replace img source by the data-uri Nachdem alles vorbereitet ist, ist die clientseitige Logik mit ein paar Zeilen JavaScript und CSS recht simpel. Die Idee ist, dynamisch die voll aufgelösten Bilder per JavaScript zu laden und mit dem onLoad Event sichtbar zu machen.","tags":"Meta","url":"https://blog.schawe.me/image-preview.html","loc":"https://blog.schawe.me/image-preview.html"},{"title":"jsnake","text":"Bisher habe ich immer nur kurze Fragmente in JavaScript geschrieben, die meist nur Gimmicks bezweckten oder Bibliotheken aufrufen. JavaScript ist im Moment möglicherweise die wichtigste Sprache: Schließlich ist sämtlicher clientseitiger Code des Webs JavaScript — und dank Node wohl auch nennenswerte Teile des Servercodes. Zumindest macht man nichts falsch, wenn man sich etwas mit JavaScript vertraut macht. Deshalb ist das neuste — und simpelste — Mitglied meiner Snake Sammlung [ 1 , 2 , 3 , 4 ] in JavaScript gehalten. Ausprobieren kann man es gleich hier: In der Spielwelt herrschen helikale Randbedingungen, hauptsächlich weil es etwas anderes ist als gewöhnliche periodische Ränder. Außerdem hat es den Vorteil, dass man keinen Pause-Modus braucht, weil diese Randbedingungen dafür sorgen, dass die Schlange sich nicht beißt, wenn man sie einfach geradeaus laufen lässt. Ich habe gehört, dass JavaScript sich in den letzten Jahren stark weiterentwickelt hat. Tatsächlich scheint mir diese Sprache einige interessante Sprachelemente erhalten zu haben, wie arrow functions x => x*x für lambdas oder den spread operator ... den ich am ehesten mit Pythons splat * vergleichen möchte. Ich will nicht behaupten, dass das folgende kartesische Produkt der beste Code oder leserlich wäre, aber interessant allemal: let SIZE = 3 ; let numbers = [... Array ( SIZE ). keys ()]; let a = []. concat ( ... numbers . map ( x => numbers . map ( y => [ x , y ] ) ) ); console . log ( a ); Anscheinend gibt es mit der nächsten geplanten Version ( ES6 ) noch mehr nette Sprachelemente. Unter anderem Module . Ich bin geradezu sprachlos, dass man bisher keine Sprachunterstützung für die Verteilung des Quellcodes über mehrere Dateien hatte. Anscheinend bin ich noch zu sehr von den Konzepten der \"C-artigen\" Sprachen beeinflusst. Da jsnake nur ein paar Zeilen in einer Datei sind und sich ein ganzes GitHub Repository deshalb nicht lohnt, habe ich es in einen Gist hochgeladen.","tags":"Code","url":"https://blog.schawe.me/jsnake.html","loc":"https://blog.schawe.me/jsnake.html"},{"title":"png2gif","text":"Konvertiere einen Ordner voller .png in ein animiertes .gif convert -delay 30 -loop 0 -layers Optimize *.png out.gif Natürlich klappt das nicht nur für .png und alle anderen Optionen von Imagemagick lassen sich kombinieren. convert -resize 256x256 \\> -delay 30 -loop 0 -layers Optimize *.svg out.gif","tags":"Snip","url":"https://blog.schawe.me/png2gif.html","loc":"https://blog.schawe.me/png2gif.html"},{"title":"rsnake","text":"In meinem letzten Einträgen ist bereits angeklungen, dass ich Rust mag. Und wie die Erfahrung [ 1 , 2 , 3 ] zeigt, dauert es nie lange bis ich eine Snake-Abwandlung programmiere. Dieses Mal verfolgt der Autopilot die Strategie des smart kinetic walk , (ein Model aus der statistischen Physik zur Simulation von Polymeren,) um sich nicht selbst zu beißen — leider setzt diese Strategie ein unendlich großes Spielfeld voraus. Die grundlegende Idee ist, dass die Schlange immer wenn sie sich selbst begegnet prüft welcher nächste Schritt sie in einer Schlaufe fängt und welcher nach außen führt. Mit offenen Randbedingungen, also auf einem unendlich großen Feld lässt sich dass das in konstanter Zeit erledigen, wenn die Schlange an jedem Segment ihres Körpers die Anzahl der Rechts- und Linksdrehungen speichert. Bei periodischen Randbedingungen funktioniert das allerdings nicht mehr, sodass der Autopilot eine Best-First-Search durchführt. Auf offenen Randbedingungen würde es ausreichen einen Weg vom potentiell nächstem Schritt zu einem beliebigen Punkt außerhalb eines Rechtecks, das die Schlange einschließt, zu finden. Bei periodischen Randbedingungen ist es nicht so eindeutig. Ich habe mich entschlossen, dass die Schlange sich nur so bewegen soll, dass immer ein Pfad zu ihrem Schwanz existiert. Tatsächlich führt diese Strategie zu unterhaltsamen und nicht perfekten Spielverläufen. Your browser does not support the video tag. Der Vollständigkeit halber sind noch ein nicht vorausplanender und ein perfekter, aber langweiliger, Autopilot dabei. Da die Quellen auf GitHub liegen, ist es nur vier Zeilen entfernt — weniger, wenn der Rustcompiler bereits installiert ist. # curl https://sh.rustup.rs -sSf | sh # never copy `| sh` in your terminal git clone https://github.com/surt91/rsnake cd rsnake cargo run --release","tags":"Code","url":"https://blog.schawe.me/rsnake.html","loc":"https://blog.schawe.me/rsnake.html"},{"title":"Progressive Web App","text":"Seit Anfang September ist dieses Blog eine Progressive Web App . Das bedeutet, dass dieses Blog nun auch offline funktioniert und man es auf dem Smartphone als App hinzufügen kann. Warum? Nun, Chrome bietet mit Lighthouse Ratschläge, wie man seine Website verbessern kann. Einer der vier Unterpunkte heißt Progressive Web App und war frustrierend schlecht bewertet. Die folgenden Schritte habe ich also nur für Lighthouse gemacht und es hat sich auf jeden Fall gelohnt: Wie? Lighthouse bietet eine Checkliste, auf der neben einigen Punkten, die generell eine gute Idee sind, drei Punkte aufgeführt sind, die erfüllt sein müssen: Site is served over HTTPS Dank Let's Encrypt ist das kein Problem mehr. The start URL (at least) loads while offline Das ist der aufwendigste Teil. Um dies zu erreichen muss man einen service worker registrieren. Damit der service worker weiß, welche Dateien notwendig sind, benutze ich nach jedem erfolgreichen Build sw-precache mit einer sehr einfachen Konfiguration . Dadurch benötige ich jetzt Node, um das Blog zu erstellen ¯\\_(ツ)_/¯ Metadata provided for Add to Home screen Damit ist eine manifest.json gemeint. Diese Datei enthält links zu Icons, die als Appsymbol benutzt werden, wenn man die Seite auf Android oder Windows installiert. Und es legt die Farbe der Adressleiste im mobilen Chrome fest. Ein nützlicher Dienst, um ein solches Manifest zu erstellen, ist app-manifest.firebaseapp.com Was jetzt? Service Worker ermöglichen Benachrichtigungen von einer Website. Ein natürlicher nächster Schritt wäre es also Benachrichtigungen zu versenden, wenn ein neuer Post online ist. Auf der anderen Seite bin ich selbst immer etwas genervt von Websites, die mich benachrichtigen wollen und der Lighthouse Punktestand ist schon optimal, also wird das wohl nicht passieren.","tags":"Meta","url":"https://blog.schawe.me/progressive-web-app.html","loc":"https://blog.schawe.me/progressive-web-app.html"},{"title":"Push to Publish 2","text":"Nachdem ich vor Kurzem einen euphorischen Eintrag über mein automatisiertes Update dieses Blogs via Travis- CI und GitHub pages geschrieben habe, bin ich jetzt auf eine einfachere Lösung gestoßen. Alles unter einem Dach bei Netlify Es gibt einen einfachen Buildservice, der zwar nicht so flexibel ist wie Travis- CI , aber für dieses Blog ausreicht. Netlify baut die Seite also bei jedem Push in ein beobachtetes GitHub Repository. Nach Konfiguration des DNS und einem weiteren Knopfdruck ist die Seite mit einem SSL Zertifikat von Let's Encrypt ausgestattet und erreichbar. Also Bonus kann man selbst HTTP -Header bestimmen über eine _headers Datei: /* Strict - Transport - Security : max - age = 31536000 ; includeSubDomains Also kann man HTTP /2 Server Push ausprobieren, ohne einen Server betreiben zu müssen.","tags":"Meta","url":"https://blog.schawe.me/push-to-publish-b.html","loc":"https://blog.schawe.me/push-to-publish-b.html"},{"title":"png2vp9","text":"Konvertiere einen Ordner voller .png in ein zur Web-Wiedergabe geeignetes VP9 , das von allen wichtigen Browsern unterstützt wird. ffmpeg -f image2 -pattern_type glob -i \"img*.png\" -c:v libvpx-vp9 -pass 1 \\ -b:v 1000K -threads 1 -speed 4 -tile-columns 0 -frame-parallel 0 \\ -auto-alt-ref 1 -lag-in-frames 25 -g 9999 -aq-mode 0 -an -f null - ffmpeg -f image2 -pattern_type glob -i \"img*.png\" -c:v libvpx-vp9 -pass 2 \\ -b:v 1000K -threads 1 -speed 0 -tile-columns 0 -frame-parallel 0 \\ -auto-alt-ref 1 -lag-in-frames 25 -g 9999 -aq-mode 0 -c:a libopus -b:a 64k \\ -f webm video.webm Für maximale Kompatibilität kann als Fallback noch ein MP4 erstellt werden. ffmpeg -an -f image2 -pattern_type glob -i \"img*.png\" -vcodec libx264 \\ -pix_fmt yuv420p -profile:v baseline -level 3 video.mp4 Einbettung erfolgt mit: < video > < source src = \"path/to/video.webm\" type = \"video/webm; codecs=vp9,vorbis\" > < source src = \"path/to/video.mp4\" type = \"video/mp4\" > </ video >","tags":"Snip","url":"https://blog.schawe.me/png2vp9.html","loc":"https://blog.schawe.me/png2vp9.html"},{"title":"Push to Publish","text":"Seit Anfang August wird dieses Blog nicht mehr von einem Raspberry aus den eigenen vier Wänden ausgeliefert , sondern von GitHub pages. Da die Quellen dieses Blogs bereits auf GitHub sind, ist dies ein konsequenter Schritt. Hosting auf GitHub Pages GitHub bietet hosting von statischen Seiten an, was perfekt zu diesem Pelican Blog passt. Die Verwaltung ist denkbar einfach: Für jedes Repository ist der Branch gh-pages unter [username].github.io/[reponame] , hier z.B. surt91.github.io/blog , erreichbar. Will man unter einer eigenen Domain erreichbar sein, reicht es aus, im DNS für die Domain einen CNAME Eintrag auf [username].github.io anzulegen und im root des gh-pages Branches eine Datei CNAME mit der eigenen Domain anzulegen, hier z.B. echo blog.schawe.me > CNAME Primär dient GitHub pages dazu Jekyll Seiten zu erstellen und auszuliefern, was zu Konflikten führen kann, wenn man einfach nur statische Seiten im gh-pages Branch vorhält. Dies lässt sich einfach vermeiden, indem man eine Datei .nojekyll im root anlegt. Automatische Erstellung durch Travis CI Natürlich könnte man das statische HTML auf einem lokalen Computer erstellen und per Hand in den gh-pages Branch pushen. Aber man kann das auch einem Dienst wie Travis CI überlassen. Die Idee ist, dass jedes Mal wenn man die Quellen seiner Seite ändert — im Fall von Pelican werden die Blogeinträge in Markdown geschrieben und dann in HTML konvertiert — ein Server die Seite erstellt und das Ergebnis in den gh-pages Branch pusht. Dadurch wird ein Update der Website auf ein einfaches git push reduziert. Die Konfiguration von Travis CI wird durch eine denkbar einfache YAML Datei definiert. Eine (vereinfachte) Konfiguration für dieses Blog sieht beispielsweise so aus: # pelican is a python program language : python python : - \"3.5\" # install pelican and some more packages install : \"pip install -r requirements.txt\" # generate static html through pelican's makefile script : - make publish # deploy to github pages deploy : provider : pages skip_cleanup : true github_token : $GITHUB_TOKEN local_dir : output on : branch : master Falls Fehler beim Erstellen auftreten, schickt Travis eine Email und bricht die Veröffentlichung ab. Wenn keine Fehler auftreten, wird wenige Sekunden später die neue Version von GitHub ausgeliefert. SSL verschlüsselt von Cloudflare® Die github.io Domains werden zwar verschlüsselt ausgeliefert, aber natürlich kann GitHub keine SSL Zertifikate für die eigene Domain ausstellen lassen. [Update: Mittlerweile kann GitHub das.] Man kann auch kein eigenes Zertifikat hochladen. Aber die Situation ist nicht so aussichtslos wie sie scheint. Cloudflare ermöglicht es, allerdings müssen ein paar Bedingungen erfüllt sein. Cloudflare muss als DNS Service für die gewünschte Domain genutzt werden und als Proxy vor der Seite benutzt werden. Als Bonus können wir Cloudflares CDN nutzen. Sobald sich Cloudflare um das DNS der Domain kümmert, kann über das Dashboard SSL aktiviert werden — und wenn man schon dabei ist, sollte man auch die Always use HTTPS und HSTS Optionen aktivieren.","tags":"Meta","url":"https://blog.schawe.me/push-to-publish.html","loc":"https://blog.schawe.me/push-to-publish.html"},{"title":"Vicsek","text":"Das Vicsek-Modell wurde 1995 vorgeschlagen, um das Schwarmverhalten von Vögeln oder Fischen zu modellieren. Die Idee ist, dass jedes Individuum seine Bewegungsrichtung an der seiner Nachbarn anpasst. Wenn jedes Individuum genügend Nachbarn hat und die Störeinflüsse nicht zu groß sind, bilden sich Schwärme. Videos von solchen Schwärmen werden auf allen größeren Konferenzen der Statistischen Physik gezeigt — und jetzt auch hier. Your browser does not support the video tag. Auf GitHub findet sich das Programm, das ich für obiges Video geschrieben habe. Es ist in Rust geschrieben und zeigt die Simulation per Piston auf dem Bildschirm. Ich habe sehr großen Gefallen an Rust gefunden — gerade für ein Projekt wie dieses scheint es ideal geeignet. Es ist so schnell wie C, aber man muss sich keinerlei Gedanken um den Speicher machen und einige andere Fehlerklassen, die der Compiler direkt verhindert. Rayon macht Parallelisierung so einfach wie OpenMP — mit dem Vorteil, dass der Compiler einen Fehler ausgibt, falls es eine Variable gibt, aus der parallel gelesen und geschrieben wird. Als Beispiel, warum ich Rust als sehr leserlich und elegant empfinde, möchte ich folgendes (unvollständige) Beispiel ansehen. pub enum Proximity { Neighbors ( usize ), Radius ( f64 ) } pub struct Vicsek { proximity : Proximity , } impl Vicsek { fn update ( bird : & mut Bird ) { match self . proximity { Proximity :: Neighbors ( n ) => self . update_direction_neighbors ( bird , n , noise ), Proximity :: Radius ( r ) => self . update_direction_disk ( bird , r , noise ), } } } Die Methode update() passt die Richtung an, in die ihr Argument im nächsten Zeitschritt fliegen soll. In meiner Simulation gibt es zwei Möglichkeiten: entweder orientiert man sich an seinen n nächsten Nachbarn oder an allen Vögeln innerhalb eines Radius von r . Der Datentyp Proximity kann eines von beiden beinhalten — welches vorhanden ist, kann elegant per Pattern-Matching ermittelt werden. Brauche ich länger, um Rust zu schreiben als C oder C++? Vermutlich, aber ich verbringe weniger Zeit mit dem Debuggen. Netto also mehr Spaß.","tags":"Code","url":"https://blog.schawe.me/vicsek.html","loc":"https://blog.schawe.me/vicsek.html"},{"title":"A Graph a Day","text":"Vor einiger Zeit habe ich @randomGraphs geschrieben: Ein Twitterbot, der einen Zufallsgraphen pro Tag tweetet. Die meisten Graphtypen, die er darstellen kann stammen aus der NetworkX Bibliothek oder sind reale Netzwerke. Ein paar Proximity Graphs habe ich selbst geschrieben. Die Darstellung und gegebenenfalls das Layout übernimmt Cytoscape oder graph-tool (dessen Autor diesem Bot folgt). Bei diesem Projekt habe ich exzessiv Gebrauch von Pythons Decorator und Introspection gemacht, sodass man, um einen neuen Graphtyp einzuführen nur eine Methode schreiben muss, die eine Graph-Datenstruktur zurück gibt. Einstellungen, welche Darstellungen erlaubt sind, werden per decorator getätigt und alle Methoden werden per Introspection automatisch zum Pool hinzugefügt, aus dem der Zufallsgenerator zieht. Eine typische Methode sieht etwa so aus. @synonym ( \"Barabasi Albert\" ) @synonym ( \"preferential attachment\" ) @style ( styles_all ) @layout ([ \"kamada-kawai\" , \"force-directed\" , \"sfdp\" , \"fruchterman_reingold\" , \"arf\" , \"radial_tree\" ]) def generateBarabasiAlbert ( self , N = None , m = None , ** kwargs ): if N is None : N = random . randint ( 4 , 400 ) if m is None : m = random . randint ( 1 , 5 ) G = gen . barabasi_albert_graph ( N , m ) # gen is networkx Generator details = dict ( name = \"Barabási-Albert Graph\" , N = N , m = m , seed = self . seed , template = \" {name} , N = {N} , m = {m} \" ) return G , details Und liefert für $N=226, m=1$ und das radial_tree Layout beispielsweise diesen Graph. Die Größe der Knoten wird hier von der Betweenness Centrality bestimmt. Die @synonym Decorators ermöglichen die zweite Funktion des Bots, denn er tweetet nicht nur einmal am Tag einen zufälligen Graphen, sondern reagiert auch auf Mentions. Falls in der Mention der Name der Methode oder eines der per @synonym registrierten Worte auftaucht, antwortet er mit einem Bild des entsprechenden Graphen. Dank fuzzywuzzy ist es sogar resistent gegen Tippfehler. Twitter unterstützt leider keine Vektorgrafiken und wandelt Bilder gerne in stark komprimierte .jpg , was gerade bei diesen Graphen zu störenden Artefakten führt. Dagegen hilft es, wenn ich einen Rand aus transparenten Pixeln dem Bild hinzufüge. Das führt dazu, dass Twitter .jpg nicht als geeignetes Format ansieht und die Bilder im verlustfreien .png ausliefert. convert -alpha on -channel RGBA -bordercolor \"rgba(0,0,0,0)\" -border \"1x1\" input.png output.png Der komplette Quellcode ist auf Github .","tags":"Code","url":"https://blog.schawe.me/randomGraphs.html","loc":"https://blog.schawe.me/randomGraphs.html"},{"title":"make","text":"Als Obi-Wan zu Luke gesagt hat This is the weapon of a Jedi Knight. Not as clumsy or random as a blaster; an elegant weapon for a more civilized age. — Obi-Wan Kenobi (1977) Meinte er vermutlich make . (Fun Fact: make wurde auch 1977 veröffentlicht .) Mit wenigen Zeilen im Makefile kann man nicht nur sein $\\LaTeX$ Projekt kompilieren, sondern auch alle Plots neu zeichnen, die sich geändert haben. Für unser Beispiel gehen wir davon aus, dass zum Plotten Gnuplot mit dem epslatex Terminal genutzt wird und folgende Verzeichnisstruktur des Projektes vorliegt. . +-- data | + datafile1.dat | + datafile2.dat +-- images | +-- img1.svg | +-- img2.tex +-- plots | +-- style.gps | +-- plot1.gp | +-- plot2.gp +-- myDocument.tex +-- chapter1.tex +-- chapter2.tex +-- lit.bib Dann kümmert sich das folgende Makefile darum, dass die Daten für die Plots heruntergeladen werden, alle Plots, TikZ und .svg parallel zu .pdf gerendert werden und sobald das geschehen ist, das Dokument kompiliert wird. DOCUMENT = myDocument # get all image files from their directories PLOTS := $( wildcard plots/*.gp ) TIKZ := $( wildcard images/*.tex ) SVG := $( wildcard images/*.svg ) # we want the images to be pdf PLOTS := $( PLOTS:%.gp = %.pdf ) SVG := $( SVG:%.svg = %.pdf ) TIKZ := $( TIKZ:%.tex = %.pdf ) IMAGES := $( PLOTS ) $( SVG ) $( TIKZ ) # get all tex files TEX := $( wildcard *.tex ) BIBFILE := lit.bib all : $( DOKUMENT ) . pdf # we need chapters, images and the bib file to create our document # also recompile, whenever one of those changes $(DOCUMENT).pdf : $( TEX ) $( IMAGES ) $( BIBFILE ) $(DOCUMENT).pdf : %. pdf : %. tex pdflatex -interaction = batchmode $* > /dev/null biber $* > /dev/null pdflatex -interaction = batchmode $* > /dev/null pdflatex -interaction = batchmode $* > /dev/null # gnuplot generates texfiles from the .gp files # make sure to regenerate all tex files, if the style # or the data changes %.tex : %. gp plots / style . gps | data cd $( <D ) && gnuplot $( <F ) > /dev/null 2 > & 1 # use this rule to convert .svg to pdf $(SVG) : %. pdf : %. svg cd $( <D ) && inkscape -z -A $( *F ) .pdf -h 1080 $( <F ) # use this rule only to generate .pdf from the \"image type\" .tex files $(TIKZ) $(PLOTS) : %. pdf : %. tex cd $( <D ) && pdflatex -interaction = batchmode $( <F ) > /dev/null rm -f $* . { log,aux } $* -inc.eps $* -inc-eps-converted-to.pdf # rule to extract data from its archive data : %: %. tar . xz tar -xf $< # rule to download the archive with the data %.tar.xz : wget -nv https://some.domain.tld/where/your/data/is/ $@ clean : proper rm -rf data rm -f $( DOCUMENT ) .pdf # delete temporary files proper : rm -f data.tar.xz rm -f $( PLOTS ) $( PLOTS:.pdf = .eps ) *-inc.eps *-inc-eps-converted-to.pdf $( PLOTS:.pdf = .tex ) plots/fit.log $( TIKZ ) $( SVG ) rm -f { $( DOCUMENT ) } . { log,aux,bbl,blg,toc,out,lof,lot,snm,nav,tec,glg,glo,gls,xdy,acn,acr,alg,bcf,run.xml } Dazu baut make einen gerichteten azyklischen Graphen ( DAG ) aus den Abhängigkeiten auf und führt die Dinge, deren Abhängigkeiten erfüllt sind, parallel aus. Das grundlegende Element einer Makefile sind die Rules, die generell so aufgebaut sind targets : prerequisites < tab > recipe Dabei gibt die erste Zeile die Abhängigkeiten welche prerequisites bestehen müssen, um durch Ausführung des recipe die targets zu erstellen. Die Nützlichkeit von make wird zu großen Teilen durch automatische Variablen (zB. $* ) oder Pattern Rules ( %.pdf ) hergestellt. Dazu verweise ich allerdings lieber auf die offizielle Dokumentation .","tags":"Code","url":"https://blog.schawe.me/make.html","loc":"https://blog.schawe.me/make.html"},{"title":"Labyrinthartiger Zellulärer Automat","text":"Der wohl berühmteste zelluläre Automat ist vermutlich Conway's Game of Life . Er und nahe Verwandte sind geradezu lächerlich gut untersucht. Das LifeWiki gibt einen ganz guten Überblick. Die Regeln sind einfach: Jede Zelle hat 8 Nachbarn, wenn genau 3 Nachbarn leben, erwacht sie auch zum Leben, bei weniger als 2 oder mehr als 3 stirbt sie (23/3). Wenn man die Regeln des Automaten ändert, kann man mit 12345/3 labyrinth artige Strukturen erzeugen. Your browser does not support the video tag. Der Code ist als Gist auf GitHub verfügbar.","tags":"Code","url":"https://blog.schawe.me/labyrinthartiger-zellularer-automat.html","loc":"https://blog.schawe.me/labyrinthartiger-zellularer-automat.html"},{"title":"Relative Neighborhood Graph","text":"Your browser does not support the video tag. Zu jedem Zeitpunkt ist im obigen Video ein Relative Neighborhood Graph ( RNG ) zu sehen. Der RNG verbindet Knoten miteinander, die nahe beieinander sind. Für die Knotenmenge $V$ muss also eine Metrik definiert sein, sodass eine Distanz $d_{ij}$ zwischen zwei Knoten definiert ist. Dann verbindet der RNG alle Knoten, die die Bedingung $$ d_{ij} \\le \\max(d_{ik}, d_{kj}) \\quad \\forall k \\in V\\setminus{i, j} $$ erfüllen. Dementsprechend simpel kann man einen RNG erzeugen. import random import networkx as nx import matplotlib.pyplot as plt def dist ( n1 , n2 ): \"\"\"Euclidean distance\"\"\" return (( n1 [ 0 ] - n2 [ 0 ]) ** 2 + ( n1 [ 1 ] - n2 [ 1 ]) ** 2 ) ** 0.5 def rng ( G ): \"\"\"Insert edges according to the RNG rules into the graph G\"\"\" for c1 in G . nodes (): for c2 in G . nodes (): d = dist ( c1 , c2 ) for possible_blocker in G . nodes (): distToC1 = dist ( possible_blocker , c1 ) distToC2 = dist ( possible_blocker , c2 ) if distToC1 < d and distToC2 < d : # this node is in the lune and blocks break else : G . add_edge ( c1 , c2 ) if __name__ == \"__main__\" : # generate some random coordinates coordinates = [( random . random (), random . random ()) for _ in range ( 100 )] G = nx . Graph () for x , y in coordinates : G . add_node (( x , y ), x = x , y = y ) rng ( G ) # draw the graph G pos = { n : ( n [ 0 ], n [ 1 ]) for n in G . nodes ()} nx . draw_networkx_nodes ( G , pos = pos , node_shape = \"o\" ) nx . draw_networkx_edges ( G , pos = pos ) plt . show () Interessanterweise tauchen alle Kanten des RNG auch in der Delaunay Triangulation der gleichen Knotenmenge auf. Dies kann man nutzen, um RNGs in $\\mathcal{O}(N \\log N)$ zu konstruieren. Meiner persönlichen Meinung nach, bildet der RNG mit dem Verhältnis von Knoten zu Kanten ein ästhetisches Optimum.","tags":"Code","url":"https://blog.schawe.me/relative-neighborhood-graph.html","loc":"https://blog.schawe.me/relative-neighborhood-graph.html"},{"title":"optipng","text":"Optimiere .png Bilder. Kleinere Größe, kein Qualitätsverlust. optipng -o7 *.png","tags":"Snip","url":"https://blog.schawe.me/optipng.html","loc":"https://blog.schawe.me/optipng.html"},{"title":"Perfect Dependencies","text":"Man hat ein großes C++ Projekt, ändert einen Header, führt make aus und ein seltsamer Fehler tritt im Programm auf. Das liegt natürlich daran, dass make nicht alle Quelldateien neu kompiliert hat, die den Header einbinden. Woher sollte make das auch wissen? Alle Header per Hand in der Makefile einzutragen und zu pflegen, ist Wahnsinn und wird den Programmierer in denselben treiben. make ist ein sehr allgemein gehaltenes Programm, wie ich in einem vorherigen Eintrag gezeigt habe. Sich um Eigenheiten von C oder C++ zu kümmern fällt also nicht in den Aufgabenbereich von make . Aber glücklicherweise gibt es ein Programm, dessen Hauptaufgabe es ist, sich mit den Eigenheiten von C bzw. C++ auszukennen: den Compiler. Tatsächlich bietet (zumindest GCC ) die Option eine C oder C++ Datei zu parsen und alle inkludierten Header auszugeben. g++ -MM myCode.cpp Das ausnutzend, bietet die offizielle Dokumentation von GNU make folgende Rule, um je eine \"dependency\" Makefile pro .c Datei zu erzeugen und automatisch einzubinden. %.d : %. c @set -e ; rm -f $@ ; \\ $( CC ) -M $( CPPFLAGS ) $< > $@ . $$$$ ; \\ sed 's, \\( $* \\)\\. o [ : ] *, \\1 .o $@ : ,g' < $@ . $$$$ > $@ ; \\ rm -f $@ . $$$$ include $(sources:.c=.d) Falls man .o Dateien in ein obj/ Verzeichnis speichert, muss man die Regex anpassen. In meinen Projekten leistet mir diese Rule gute Dienste. Alternativ könnte man natürlich auf ein anderes Buildsystem statt handgepflegter Makefiles umsteigen.","tags":"Code","url":"https://blog.schawe.me/perfect-dependencies.html","loc":"https://blog.schawe.me/perfect-dependencies.html"},{"title":"png2mp4","text":"Konvertiere einen Ordner mit passend nummerierten .png in ein x264 Video im .mp4 Format mit gegebener Framerate. ffmpeg -f image2 -pattern_type glob -framerate 60 -i \"img*.png\" -vcodec libx264 vid.mp4","tags":"Snip","url":"https://blog.schawe.me/png2mp4.html","loc":"https://blog.schawe.me/png2mp4.html"},{"title":"svg2png","text":"Konvertiere .svg in .png mit weißem Hintergrund. inkscape -z -b \\\" #fff\\\" -e img.png -h 1080 img.svg Oder einen ganzen Ordner. for i in *.svg do inkscape -z -b \\\" #fff\\\" -e $(basename -s .svg $i).png -h 1080 $i done","tags":"Snip","url":"https://blog.schawe.me/svg2png.html","loc":"https://blog.schawe.me/svg2png.html"},{"title":"TSPview","text":"Das Problem des Handlungsreisenden ist es, die kürzeste Rundtour zu planen, sodass man alle Städte besucht. Es ist eines der berühmtesten Optimierungsprobleme und gehört zur Klasse NP -hard . Es gibt also ( bis jetzt ) keine effiziente Möglichkeit zur Lösung. Allerdings gibt es Näherungen , untere Schranken und unzählige Heuristiken. Die einfachsten dieser Heuristiken habe ich in einem kleinen Programm TSPview implementiert, mitsamt Visualisierung. Der Quellcode ist auf GitHub zu finden. Your browser does not support the video tag. Algorithmen Hier folgt eine kurze Beschreibung der verwendeten Algorithmen und jeweils ein Bild, welche Lösung die Methode auf einer berühmten Instanz des TSP findet. Das sind 42 Hauptstädte der Vereinigten Staaten von Amerika und Washington, DC (Hawaii und Alaska, sowie einige Staaten an der Ostküste, die das Problem nicht schwieriger machen, fehlen). Dieses Problem war das erste größere, das 1956 beweisbar optimal gelöst wurde. Nearest Neighbor Die Nearest Neighbor Heuristik ($\\mathcal{O}(N&#94;2)$) startet bei einer zufälligen Stadt und wählt als nächste Stadt immer die Stadt, die am nächsten an der aktuellen Stadt ist und noch nicht besucht wurde. Greedy Diese Heuristik ($\\mathcal{O}(N&#94;2 \\log N)$) ist ähnlich zu Kruskals Algorithmus für minimal spannende Bäume . Sie nimmt die kürzeste Verbindung zwischen zwei Städten und fügt sie der Tour hinzu, wenn sie in der Tour noch erlaubt ist. Farthest Insertion Farthest Insertion ($\\mathcal{O}(N&#94;3)$) startet bei einer zufälligen Stadt und fügt dann die Stadt, die am weitesten von der aktuellen Tour entfernt ist an der Stelle in die Tour, die dafür sorgt, dass die Tour möglichst kurz bleibt. Two-Opt Two-Opt beginnt mit einer beliebigen Tour, die bspw. durch eine der obigen Heuristken erstellt wurde und verbessert sie, indem sie zwei Verbindungen nimmt und die Endpunkte über Kreuz austauscht, wenn die Tour dadurch verbunden bleibt und kürzer wird. Lineare Programmierung mit \"Subtour Elimination Cuts\" Lineare Programmierung ( LP ) zu erklären, würde diesen Artikel sprengen. Aber diese Methode liefert untere Schranken für die Tourlänge und kann somit benutzt werden, um die Qualität einer heuristischen Lösung abzuschätzen. Falls man die optimale Lösung durch lineare Programmierung findet, erkennt man sie auch sofort als optimal. Für weitere Details, kann ich auf einen arXiv Artikel von mir verweisen. Concorde Concorde ist der \"State of the Art\" Solver für das Problem des Handlungsreisenden und löst problemlos Instanzen mit mehr als 1000 Städten. Intern benutzt es zwar eine Menge Heuristiken, allerdings auch lineare Programmierung, um nachzuweisen, dass die gefundene Lösung optimal ist. Technische Details TSPview ist ein Python3 Programm, das zur Darstellung PyQt5 benutzt, das sich per pip3 install PyQt5 einfach installieren lässt. Darüber hinaus enthält es eine optionale Abhängigkeit zu CPLEX , einem kommerziellen LP solver. boost::python Da das Hauptprogramm in Python geschrieben ist, aber der LP -Teil in C++, braucht man eine Möglichkeit der Kommunikation. Glücklicherweise gibt es mit boost::python eine Möglichkeit C++ Klassen in Python als Python-Klassen zu benutzen. Um beispielsweise die C++ Klasse MyClass , deren Konstruktor einen Integer und eine Python-Liste entgegen nehmen soll, in Python benutzen und myMethod aufrufen zu können, reicht folgender Code: #include <boost/python.hpp> namespace py = boost :: python ; // implement MyClass BOOST_PYTHON_MODULE ( MyClass ) { py :: class_ < MyClass > ( \"MyClass\" , py :: init < int , py :: list > ()) . def ( \"myMethod\" , & MyClass :: myMethod ) ; }","tags":"Code","url":"https://blog.schawe.me/tspview.html","loc":"https://blog.schawe.me/tspview.html"},{"title":"Blogumzug","text":"Soeben habe ich mein Blog von Blogger auf einen kleinen Raspberry Pi 2 in meiner Wohnung verschoben. Als Engine benutze ich Pelican , ein statischer Blog Generator in Python, der mir auf den ersten Blick sehr gefällt. Nicht nur, dass ich alle Einträge jetzt in Markdown schreiben kann, was es ermöglicht das ganze Blog per git zu verwalten (dementsprechend gibt es den Quellcode auf GitHub ), sondern es steht mit Pygments ein sehr hübsches Syntax Highlighting zur Verfügung. float Q_rsqrt ( float number ) { long i ; float x2 , y ; const float threehalfs = 1.5F ; x2 = number * 0.5F ; y = number ; i = * ( long * ) & y ; // evil floating point bit level hacking i = 0x5f3759df - ( i >> 1 ); // what the fuck? y = * ( float * ) & i ; y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration // y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed return y ; } Außerdem Formeln in $\\LaTeX$ Notation dank MathJax $$\\mathcal H = \\sum_{\\left< i, j \\right>} s_i s_j$$ Ich werde diese Gelegenheit außerdem nutzen die meisten Einträge meines Blogs zu verwerfen und nur einige ausgewählte zu überarbeiten und hier zu veröffentlichen.","tags":"Meta","url":"https://blog.schawe.me/blogumzug.html","loc":"https://blog.schawe.me/blogumzug.html"},{"title":"SimulatedSort","text":"Simulated Annealing ist eine Optimierungsmethode, die von natürlichen Kristallisationsprozessen inspiriert ist. Man startet in der Schmelze bei hohen Temperaturen und lässt es dann abkühlen, sodass die Atome sich in einem Zustand minimaler Energie anordnen, dem Kristallgitter. Wenn man also für ein Optimierungsproblem die zu optimierende Größe als Energie ansieht, und man eine Lösung durch eine kleine Änderung in eine andere Lösung verwandeln kann, kann man mit dieser Methode eine Näherung für das Optimum finden. Wenn wir also eine Sequenz $S$ von $N$ Zahlen sortieren wollen, können wir die Summe der Differenzen zwischen benachbarten Zahlen als Energie betrachten, denn die ist minimal in einer sortierten Liste. \\begin{equation} \\mathcal{H} = \\sum_{i=1}&#94;{N-1} \\left| S_i - S_{i+1} \\right| \\end{equation} Um eine Lösung in eine andere zu verwandeln, reicht es zwei Elemente der Sequenz zu tauschen. Der Kern von Simulated Annealing ist der Metropolis Algorithmus. Starte bei einer hohen Temperatur $T$. Berechne die Energie $\\mathcal{H}(S)$ der aktuellen Konfiguration $S$. Erzeuge eine neue Konfiguration $R$ durch eine kleine Änderunge von $S$. Akzeptiere $R$ mit der Wahscheinlichkeit $$p_\\mathrm{acc} = \\min\\left[1 ,\\exp(-(\\mathcal{H}(R) - \\mathcal{H}(S))/T) \\right],$$ sodass eine \"sortiertere\" Sequenz immer akzeptiert wird und eine \"unsortiertere\" vor allem bei hohen Temperaturen. Wenn $R$ akzeptiert wird, gilt $S:=R$, ansonsten wir die alte Konfiguration $S$ weiter benutzt. Reduziere die Temperatur (beispielsweise durch Multiplikation mit einer Zahl etwas kleiner als 1) und breche ab, wenn die Zieltemperatur erreicht ist. Ansonsten beginne wieder bei Punkt 2. Genug der Theorie: In einem Gist auf GitHub präsentiere ich ein schnell terminierendes Sortierprogramm, das zwar nicht immer eine sortierte Liste findet, aber zumindest eine Näherung! Es ist also Bogosort in mehr als nur einer Hinsicht überlegen! Wer braucht da noch $\\mathcal{O}(N \\log(N))$ Sortier-Algorithmen?!","tags":"Code","url":"https://blog.schawe.me/simulatedsort.html","loc":"https://blog.schawe.me/simulatedsort.html"},{"title":"SHA -256 in 256 Zeilen","text":"Programmiersprachen muss man üben, um sie zu lernen und um sie nicht wieder zu vergessen. Ich habe also meine Zeit damit vertrieben einen SHA -256 zu schreiben — eine kryptographische Hash Funktion. Die Spezifikation ist glücklicherweise sehr sehr verständlich. Und auch wenn es tausende andere Implementationen gibt, die schneller sind, alle Grenzfälle beachten (ich befürchte, dass mein Programm Probleme auf Big Endian Systemen bekommt), und sogar Schaltkreise, die hochoptimiert nur diese Operation beherrschen (Stichwort: Bitcoin ASIC ), ist meiner dennoch sehenswert, da er SHA -256 in 256 Zeilen darstellt. Der Code ist als Gist auf GitHub , da er in seinen 256 Zeilen ansonsten den Lesefluss stören würde. In Python ist es übrigens etwas kürzer. print ( hashlib . sha256 ( b \"Hallo Welt!\" ) . hexdigest ())","tags":"Code","url":"https://blog.schawe.me/sha-256-in-256-zeilen.html","loc":"https://blog.schawe.me/sha-256-in-256-zeilen.html"},{"title":"DGLshow","text":"Nachdem ich so vielen Differenzialgleichungssystemen [ 1 , 2 , 3 , 4 ] begegnet bin, die sich nicht analytisch lösen lassen, habe ich mir ein Programm zur numerischen Lösung und Visualisierung derselben geschrieben . ![Doppelpendel](/img/doublePendulum.png) Die grundlegende Idee zur numerischen Lösung von Differentialgleichungen ist es, die Zeit in diskreten Schritten $\\tau$ vergehen zu lassen. Nach jedem Schritt wird der Zustand so geändert, als ob sich während des Zeitschrittes nichts geändert hätte und die \"Kräfte\" werden entsprechend der Bewegungsgleichungen neu berechnet. Für infinitesimal kleine $\\tau \\to \\mathrm{d}t$ ist diese Methode schließlich exakt. Im einfachsten Fall, dem Euler Verfahren, sähe das für ein einfaches Fadenpendel nach $k$ Zeitschritten so aus \\begin{align } \\ddot\\vartheta_{k+1} &= - mgl \\sin(\\vartheta_k)\\ \\dot\\vartheta_{k+1} &= \\tau \\ddot\\vartheta_{k} + \\dot\\vartheta_{k}\\ \\vartheta_{k+1} &= \\tau \\dot\\vartheta_{k} + \\vartheta_{k} \\end{align } Unglücklicherweise hat dieses Verfahren ernsthafte Probleme mit der Energieerhaltung und braucht sehr kleine $\\tau$ für brauchbare Ergebnisse. Es gibt deutlich ausgefeiltere Methoden, wie den klassischen Runge-Kutta Algorithmus. Es gibt Methoden, den Zeitschritt $\\tau$ während der Simulation adaptiv anzupassen, um nur wenig Rechenaufwand in den wenig fehleranfälligen Phasen zu verbringen. Es gibt spezialisierte Methoden, die sehr gut für bestimmte Bewegungsgleichungen funktionieren, wie Velocity-Verlet , der oft für Molekulardynamiksimulationen eingesetzt wird. Chaotische Systeme haben in der Regel etwas kompliziertere Bewegungsgleichungen. Das oben abgebildete Doppelpendel etwa wird, wie ich in einem anderen Post beschrieben habe durch folgendes Ungetüm beschrieben. \\begin{align } \\ddot\\theta_1 &= \\frac{m_2 \\cos(\\theta_1 - \\theta_2) (l_1 \\sin(\\theta_1 - \\theta_2) \\dot\\theta_1&#94;2 - g \\sin(\\theta_2)) + m_2 l_2 \\sin(\\theta_1 - \\theta_2) \\dot\\theta_2&#94;2 + (m_1 + m_2) g \\sin(\\theta_1)}{m_2 l_1 \\cos&#94;2(\\theta_1 - \\theta_2) - (m_1+m_2) l_1} \\ \\ddot\\theta_2 &= \\frac{m_2 l_2 \\cos(\\theta_1 - \\theta_2) \\sin(\\theta_1 - \\theta_2) \\dot\\theta_2&#94;2 + (m_1+m_2) l_1 \\sin(\\theta_1 - \\theta_2) \\dot\\theta_1&#94;2 + (m_1+m_2) g \\cos(\\theta_1 - \\theta_2) \\sin(\\theta_1) - (m_1+m_2) g \\sin(\\theta_2)}{(m_1+m_2) l_2 - m_2 l_2 \\cos&#94;2(\\theta_1 - \\theta_2)} \\end{align } Anfangs empfiehlt es sich also etwas einfacheres und vertrauteres zu lösen, wie den Lorenz-Attraktor \\begin{align } \\dot{X} &= a(Y - X) \\ \\dot{Y} &= X(b - Z) - Y \\ \\dot{Z} &= XY - cZ \\ \\end{align } Oder das Dreikörperproblem \\begin{align } \\ddot{\\vec{x}_1} &= -\\frac{Gm_2}{\\left(x_1 - x_2\\right)&#94;3} (\\vec{x}_1 - \\vec{x}_2) - \\frac{Gm_3}{\\left(x_1 - x_3\\right)&#94;3} (\\vec{x}_1 - \\vec{x}_3)\\ \\ddot{\\vec{x}_2} &= -\\frac{Gm_1}{\\left(x_2 - x_1\\right)&#94;3} (\\vec{x}_2 - \\vec{x}_1) - \\frac{Gm_3}{\\left(x_2 - x_3\\right)&#94;3} (\\vec{x}_2 - \\vec{x}_3)\\ \\ddot{\\vec{x}_3} &= -\\frac{Gm_1}{\\left(x_3 - x_1\\right)&#94;3} (\\vec{x}_3 - \\vec{x}_1) - \\frac{Gm_2}{\\left(x_3 - x_2\\right)&#94;3} (\\vec{x}_3 - \\vec{x}_2)\\ \\end{align } Da man das 3-Körperproblem trivial auf ein $N$-Körperproblem erweitern kann, habe ich hier ein \"Sonnensystem\" bzw. Bohrsches \"Atom\"-modell simuliert. Um die obigen (bewegten) Bilder zu erzeugen und um ein bewegtes Doppelpendel für meinen Schreibtisch zu haben, — wennauch nur auf einem Bildschirm — habe ich in C++ einen adaptiven Runge-Kutta-4 Löser geschrieben, der mit den Qt Zeichenprimitiven animiert wird. Auch wenn der Code nicht sehr aufgeräumt ist und Startwerte im Quellcode angepasst werden müssen, sind die Quellen auf GitHub: github.com/surt91/DGLshow .","tags":"Code","url":"https://blog.schawe.me/dglshow.html","loc":"https://blog.schawe.me/dglshow.html"},{"title":"Doppelpendel","text":"Das ist ein Doppelpendel. Ein Doppelpendel ist neben dem Dreikörperproblem und dem Lorenz-Attraktor [ 1 , 2 ] das Paradebeispiel für analytisch unlösbare Bewegungsgleichungen und chaotisches Verhalten. Aus diesem Grund sollte ein Doppelpendel auf keinem Schreibtisch fehlen und bietet sich als grandiose Geschenkidee für Physiker an. Dass es analytisch unlösbar ist, lässt sich mit einem nicht rigorosen Argument anschaulich machen: Ein Blick auf die Bewegungsgleichungen: \\begin{align } (m_1 + m_2) l_1 \\ddot\\vartheta_1 + m_2 l_2 \\ddot\\vartheta_2 \\cos(\\vartheta_1 - \\vartheta_2) + m_2 l_2 \\dot\\vartheta_2&#94;2 \\sin(\\vartheta_1 - \\vartheta_2) + g(m_1 + m_2) \\sin(\\vartheta_1) &= 0\\ m_2 l_2 \\ddot\\vartheta_2 + m_2 l_1 \\ddot\\vartheta_1 \\cos(\\vartheta_1 - \\vartheta_2) - m_2 l_1 \\dot\\vartheta_1&#94;2 \\sin(\\vartheta_1 - \\vartheta_2) + m_2 g \\sin(\\vartheta_2) &= 0 \\end{align } Das sind die Differentialgleichungen für die beiden Winkel $\\vartheta_1$ und $\\vartheta_2$ des Doppelpendels. $m_i$ sind die beiden Massen und $l_i$ die Fadenlängen. Unser Ziel ist es das obige Video zu erstellen, dazu müssen wir die Bahnkurve, also $\\vartheta_1(t)$ und $\\vartheta_2(t)$ bestimmen. Dazu müssen wir die obigen Gleichungen, die sich relativ simpel, wenn auch mühsam, per Lagrange-Formalismus herleiten lassen , zunächst nach den Winkelbeschleunigungen aufgelösen. \\begin{align } \\ddot\\vartheta_1 &= \\frac{m_2 \\cos(\\vartheta_1 - \\vartheta_2) (l_1 \\sin(\\vartheta_1 - \\vartheta_2) \\dot\\vartheta_1&#94;2 - g \\sin(\\vartheta_2)) + m_2 l_2 \\sin(\\vartheta_1 - \\vartheta_2) \\dot\\vartheta_2&#94;2 + (m_1 + m_2) g \\sin(\\vartheta_1)}{m_2 l_1 \\cos&#94;2(\\vartheta_1 - \\vartheta_2) - (m_1+m_2) l_1} \\ \\ddot\\vartheta_2 &= \\frac{m_2 l_2 \\cos(\\vartheta_1 - \\vartheta_2) \\sin(\\vartheta_1 - \\vartheta_2) \\dot\\vartheta_2&#94;2 + (m_1+m_2) l_1 \\sin(\\vartheta_1 - \\vartheta_2) \\dot\\vartheta_1&#94;2 + (m_1+m_2) g \\cos(\\vartheta_1 - \\vartheta_2) \\sin(\\vartheta_1) - (m_1+m_2) g \\sin(\\vartheta_2)}{(m_1+m_2) l_2 - m_2 l_2 \\cos&#94;2(\\vartheta_1 - \\vartheta_2)} \\end{align } Diese Gleichungen sind durchaus sehr unhandlich und können nicht analytisch, gelöst werden — aber numerisch ist es kein Problem .","tags":"Code","url":"https://blog.schawe.me/double-pendulum.html","loc":"https://blog.schawe.me/double-pendulum.html"},{"title":"Ising Modell zur Bildentrauschung","text":"Eines der bekanntesten Modelle der statistischen Physik ist das Ising-Modell . Es besteht aus (klassischen) Spins auf einem Gitter im Wärmebad und soll magnetische Eigenschaften von Festkörpern modellieren. Es zeigt nämlich in 2D und 3D (und 4D … ) einen Phasenübergang zweiter Ordnung von \"magnetisch\" zu \"nicht magnetisch\", so wie ferromagnetische Materialien, die oberhalb der Curie Temperatur nicht mehr ferromagnetisch sind. In einfachen Worten: Die Spins des Ising-Modells richten sich so aus wie ihre Nachbarn und die Temperatur bringt sie wieder durcheinander. Aber es wäre natürlich langweilig das Modell so zu benutzen, wie alle anderen auch. Deshalb stelle ich hier eine Anwendung aus Pattern Recgonition and Machine Learning vor, die nichts mehr mit Magneten zu tun hat: Rauschunterdrückung in Bildern. Andererseits bin ich Physiker und darf deshalb nichts machen, was direkt nützlich wäre, also beschränke ich mich auf schwarz-weiße Bilder, die man direkt auf das \"spin up\"-\"spin down\" des Ising-Modells abbilden kann. Die Idee ist, das jeder Spin einem Pixel $x_i$ entspricht. Dann koppelt man die Spins des Ising-Modells $x_i$ an die Pixel $y_i$ des verrauschten Bildes über einen zusätzlichen Energie-Term $$\\mathcal{H} = - \\beta \\sum_{\\left< i,j \\right>} x_i x_j - \\eta \\sum_i x_i y_i.$$ Dabei bedeutet $\\left< i,j \\right>$, dass man über alle Nachbarn von $i$ summiert. Von diesem Modell kann man dann per Simulated Annealing den Grundzustand suchen oder man macht es sich einfach equilibriert bei $T=0$. Das Schema dazu wurde bereits in diesem Post gezeigt. Graue Knoten entsprechen den Pixeln des verrauschten Bilds $y_i$ und weiße Knoten den Ising-Spins $x_i$, die am Ende als Pixel des entrauschten Bilds interpretiert werden. Genug der Theorie. Es wird Zeit für pixelige Bilder. Leider hatte ich kein verrauschtes Bild, also habe ich ein beliebiges Bild gemalt und 10% aller Pixel invertiert. Links das verrauschte Bild und rechts das entrauschte. Ja, nicht perfekt. Und in dem zitierten Buch wird auf der gleichen Seite noch eine sehr viel bessere Methode angesprochen. Aber die hatte nichts mit dem Ising-Modell zu tun. Und man sieht ja auch eine Verbesserung. Oder? Nebenbei bemerkt, kann man das Ising-Modell auch als zellulären Automaten mit zufälligem Element betrachten, denn jeder Spin ist eine Zelle, die nur lokal von seinen Nachbarn und zufällig durch die Temperatur beeinflusst wird. Der Code ist als Gist auf Github .","tags":"Code","url":"https://blog.schawe.me/ising-modell-zur-bildentrauschung.html","loc":"https://blog.schawe.me/ising-modell-zur-bildentrauschung.html"},{"title":"Depth First Search und Labyrinthe","text":"Ein Algorithmus, von dem jeder schoneinmal gehört haben sollte, ist die Tiefensuche (Depth First Search). Wenn man Zusammenhangskomponenten in einem Graphen finden will oder nach einem bestimmten Knoten in einem Graphen sucht, ist die Tiefensuche meist der einfachste und oft ein geeigneter Algorithmus mit einer Zeitkomplexität $\\mathcal{O}(N+M)$, die linear in der Anzahl der Knoten und der Kanten ist. Da man gefühlt alle Graphalgorithmen am besten rekursiv beschreiben kann, folgt hier eine (nichtrigorose) Beschreibung. Man startet die Tiefensuche an einem beliebigen Knoten. Bei jedem noch nicht besuchten Nachbarn startet man wieder eine Tiefensuche. Aber was macht man im Alltag mit einer Tiefensuche? Meine Antwort darauf ist: Labyrinthe bauen. Your browser does not support the video tag. Bei dieser Gelegenheit muss NetworkX erwähnt werden. Ein Python Modul, das sehr schöne Klassen für Graphen bereitstellt und perfekt geeignet ist, um schnell Prototypen von Graphalgorithmen zu testen. Der Code ist als Gist auf GitHub verfügbar.","tags":"Code","url":"https://blog.schawe.me/depth-first-search-und-labyrinthe.html","loc":"https://blog.schawe.me/depth-first-search-und-labyrinthe.html"},{"title":"Oberflächenkachelung mit TikZ","text":"Man arbeitet an einem Seminarvortrag und will ein Modell auf einem periodischen Gitter erklären. Natürlich kann man sich nicht entscheiden, wie viele Elementarzellen man darstellen möchte. Außerdem ist es einem zuwider mehrere Elementarzellen per Hand zu schreiben. Wer kennt das nicht? Glücklicherweise gibt es eine Lösung. Weil man alle seine Aufzeichnungen sowieso in LaTeX setzt, benutzt man TikZ , bastelt eine Elementarzelle und kachelt sie über die Ebene, bis man das Gefühl hat, dass es genau passend für die Präsentation ist. Als Bonus kann man noch mit den Parametern spielen, um einen möglichst überzeugenden pseudo 3D-Effekt zu erzielen. \\documentclass { standalone } \\usepackage { tikz } \\begin { document } \\begin { tikzpicture } \\newcommand* { \\shear }{ 0.2 } \\newcommand* { \\height }{ 1.0 } \\newcommand* { \\radius }{ 0.1 } \\newcommand* { \\xspacing }{ 1 } \\newcommand* { \\yspacing }{ 0.5 } % two-dimensional lattice, with three dimensional basis % decreasing counter, otherwise there will be lines through the circles \\foreach \\x in { 4,...,0 }{ \\foreach \\y / \\dx in { 3,...,0 }{ % primitive vectors \\draw ( \\x + \\y*\\shear - \\xspacing /2 , \\y*\\yspacing ) -- ( \\x + \\y*\\shear + \\xspacing /2, \\y*\\yspacing ); \\draw ( \\x + \\y*\\shear - \\shear /2 , \\y*\\yspacing - \\yspacing /2) -- ( \\x + \\y*\\shear + \\shear /2 , \\y*\\yspacing + \\yspacing /2); \\draw ( \\x + \\y*\\shear , \\y*\\yspacing ) -- ( \\x + \\y*\\shear , \\y*\\yspacing + \\height ); % base \\fill [white] ( \\x + \\y*\\shear , \\y*\\yspacing ) circle( \\radius ); \\draw ( \\x + \\y*\\shear , \\y*\\yspacing ) circle( \\radius ); \\fill [gray] ( \\x + \\y*\\shear , \\y*\\yspacing + \\height ) circle( \\radius ); \\draw ( \\x + \\y*\\shear , \\y*\\yspacing + \\height ) circle( \\radius ); } } \\end { tikzpicture } \\end { document } Und damit wäre wiedereinmal die Vorliebe dieses Blogs für schwarz-weiße Bilder , die entweder Linien und Kreise oder zu große Pixel enthalten, bestätigt.","tags":"Code","url":"https://blog.schawe.me/oberflachenkachelung-mit-tikz.html","loc":"https://blog.schawe.me/oberflachenkachelung-mit-tikz.html"},{"title":"Rule 90","text":"Vor kurzem habe ich angefangen \" Think Complexity \" zu lesen — ein leicht verständliches, interessantes Buch, in dem unter anderem Zelluläre Automaten angesprochen werden. Und zwar die von Stephen Wolfram — ja der Stephen Wolfram, der Mathematica und Wolfram|Alpha entwickelt hat (vermutlich jedoch nicht allein). Zelluläre Automaten eignen sich natürlich sehr gut, pixelige Bilder zu erstellen, wie der Conways-Game-of-Life-Post beweist. Daher, lasse ich erstmal ein Bild sprechen. Die Idee ist, dass man mit einem eindimensionalen Zustand startet, und einen neuen Zustand daraus mit lokalen Regeln, die je einen rechten und linken Nachbarn berücksichtigen, erzeugt. Stellt man diese Zustände untereinander da, entstehen Strukturen, wie die, die an ein Sierpinski-Dreieck erinnert. Die Erklärung , wie genau diese Regeln lauten, und wie sie definiert sind, überlasse ich passenderweise Wolfram|Alpha. Und damit ich auch etwas sage, das tiefsinnig erscheint: Die Dreieckige Form entspricht übrigens dem Vorwärtslichtkegel des Startwertes in der ersten Zeile. Die $y$-Achse entspricht hier schließlich einer Zeit und die \"Lichtgeschwindigkeit\", mit der Beeinflussungen propagieren können, ist 1 Pixel pro Iteration. Den Quellcode gibt es natürlich bei GitHub . Wenn auch nur in einem \"kleine Fingerübungen in C\"-Repo. Für Liebhaber, hier noch eins im original 1982 Retro-Look. Passend zur Jahreszeit, wie ich finde.","tags":"Code","url":"https://blog.schawe.me/rule-90.html","loc":"https://blog.schawe.me/rule-90.html"},{"title":"Lissajous Figuren in Gnuplot","text":"Da nicht jeder das nötige Kleingeld für ein Oszilloskop und Funktionsgenerator hat, aber jeder gerne eine Lissajous-Figur laufen haben möchte, liefere ich hier den entsprechenden Gnuplot Code. reset set term gif animate optimize set output \"lissajous.gif\" n = 6250 set xr [ -1 : 1 ] set yr [ -1 : 1 ] set parametric unset border unset xtics unset ytics fx ( t ) = sin ( t ) fy ( t ) = sin ( 2.999 * t ) i = 0 load \"animateLissajou.gp\" set output Die Datei \" animateLissajou.gp \" sieht dann so aus: set trange [ i : i + 2 * pi ] plot fx ( t ) , fy ( t ) lc rgb 'black' notitle i = i + 2 * pi * 10 if ( i < n ) reread Stark angelehnt an diesen Blogeintrag . Das Ergenis sieht dann so aus.","tags":"Code","url":"https://blog.schawe.me/lissajous-figuren-in-gnuplot.html","loc":"https://blog.schawe.me/lissajous-figuren-in-gnuplot.html"},{"title":"Bootstrapping","text":"Wer kennt das nicht: Man hat sich ein Python Skript geschrieben, um seine Daten per Bootstrap Resampling auszuwerten und stellt fest, dass das Konstrukt zur Bildung des \"Samples mit Ersetzungen\" import random x = [ 1 , 2 , 3 ] bootstrapSample = [ random . choice ( x ) for _ in x ] einfach nicht schnell genug ist. Aber glücklicherweise gibt es numpy ! import numpy x = [ 1 , 2 , 3 ] bootstrapSample = list ( numpy . random . choice ( x , len ( x ))) Das ist — zumindest in meinem Anwendungsfall — spürbar schneller. Ich werde in Zukunft also immer optimale Fehlerbalken erzeugen.","tags":"Code","url":"https://blog.schawe.me/bootstrapping.html","loc":"https://blog.schawe.me/bootstrapping.html"},{"title":"Seltsamer Attraktor","text":"Zuvor habe ich bereits den Schmetterlingseffekt erwähnt. Um den Zusammenhang mit Chaos zu zeigen, betrachten wir folgendes Video von der Projektion in die y-z-Ebene von 13 Teilchen, die den Attraktor durchlaufen. Your browser does not support the video tag. Alle Teilchen starten auf fast dem selben Punkt, aber nehmen sehr verschiedene Wege. Nach kurzer Zeit kann man den einzelnen Teilchen nicht mehr ansehen, dass sie fast die gleichen Anfangsbedingungen hatten. Lorenz war Meteorologe und sein Differentialgleichungssystem \\begin{align} \\dot{X} &= a(Y - X) \\ \\dot{Y} &= X(b - Z) - Y \\ \\dot{Z} &= XY - cZ, \\ \\end{align} das dieses chaotische Verhalten zeigt, sollte die Atmosphäre modellieren. Jetzt kann man verstehen, was es mit dem Schmetterling aus Jurassic Park auf sich hat. Er bewegt in Peking die Flügel, und im Central Park gibt's Regen statt Sonne. — Dr. Ian Malcolm (1993) Sein Flügelschlag ändert den Zustand eines chaotischen Systems, dem Wetter, ein wenig und nach einiger Zeit hat das System einen grundlegend anderen Weg eingeschlagen, als ohne diesen Flügelschlag. Dennoch sieht das Video irgendwie geordnet aus. Fast schon vorhersagbar. Seltsam.","tags":"Code","url":"https://blog.schawe.me/seltsamer-attraktor.html","loc":"https://blog.schawe.me/seltsamer-attraktor.html"},{"title":"Dreikörperproblem","text":"Nein, ich habe keine analytische Lösung dafür gefunden. (Soweit ich mich erinnere, hat Poincaré bewiesen, dass es nicht lösbar ist.) Aber ich habe eine numerische Lösung mit dem vorher vorgestellten Runge-Kutta Löser erstellt. Und ich habe einen hübschen Film daraus gemacht. Your browser does not support the video tag. Als Standbild ist es nicht ganz so ästhetisch, wie der Lorenz-Attraktor , aber animiert ist es — meiner Meinung nach — wunderbar anzusehen. Und hier die Startwerte: (bei einer Gravitationskonstanten von 1) Blau: $M=5, x_0=0, y_0=0, v_x0=0, v_y0=0$ Rot : $M=1, x_0=1, y_0=0, v_x0=0, v_y0=1$ Grün: $M=1, x_0=1, y_0=1, v_x0=1, v_y0=0$","tags":"Code","url":"https://blog.schawe.me/dreikorperproblem.html","loc":"https://blog.schawe.me/dreikorperproblem.html"},{"title":"Schmetterlingseffekt","text":"Differentialgleichungen numerisch zu lösen macht mehr Spaß, als man erwarten würde, wenn man es hört. Und sobald man den ersten Runge-Kutta -Algorithmus in einer kommerziellen Interpretersprache geschrieben hat, bemerkt man, dass dieses Skript doch recht lange braucht. Für dieses Problem gibt es zwei Lösungen: Entweder wird man zum Guru und wendet irgendeine okkulte Matlab-Magie an, um das Programm schneller laufen zu lassen, oder man schreibt das Programm in einer schönen Sprache neu. In C zum Beispiel. Ich habe mich für den einfachen Weg entschieden und wenig überraschend eine Tempoverbesserung von Faktor $\\sim 140$ festgestellt. Jedenfalls für diesen Lorenzattraktor . \\begin{align} \\dot{X} &= a(Y - X) \\ \\dot{Y} &= X(b - Z) - Y \\ \\dot{Z} &= XY - cZ \\ \\end{align} Geplottet habe ich die Werte dann mit Python und matplotlib . Warum ich den Titel \" Schmetterlingseffekt \" gewählt habe? Naja, das Bild hier sieht ein wenig nach einem Schmetterling aus. Und tatsächlich wurde der Schmetterlingseffekt nach diesem Differentialgleichungssystem benannt — und nicht nach der Geschichte aus Jurassic Park . Er bewegt in Peking die Flügel, und im Central Park gibt's Regen statt Sonne. — Dr. Ian Malcolm (1993) Wie genau der Lorenzattraktor mit Chaos zusammenhängt, habe ich in diesem Post dargestellt . Der Quellcode ist als Gist auf GitHub .","tags":"Code","url":"https://blog.schawe.me/schmetterlingseffekt.html","loc":"https://blog.schawe.me/schmetterlingseffekt.html"},{"title":"mSnake - Noch ein Snake Clone","text":"Da ich gerade in der Uni mit Matlab zu tun habe, präsentiere ich \"stolz\" mSnake . ( Quellen bei Github ) Da ich so etwas schon in C und in Python geschrieben habe, möchte ich noch zum Ausdruck bringen, dass mir Python davon am besten gefällt. Matlab ist irgendwie anders. Vom Syntax ist es C und Python gar nicht mal unähnlich, dennoch sieht der Code (meiner jedenfalls) ganz anders aus: Aufgrund vieler spezialisierter Matrix Funktionen, ist im gesamten Programm nur eine Schleife enthalten: Die while-Schleife, die abbricht, wenn man verloren hat. Ob das jetzt gut oder schlecht ist…","tags":"Code","url":"https://blog.schawe.me/msnake.html","loc":"https://blog.schawe.me/msnake.html"},{"title":"PySnake","text":"Weihnachten. Auch wenn man sein Studium sehr mag, ist es doch schön, wenn man mal zwei Wochen frei hat (…als ob ich das irgendjemandem erklären müsste). Man kann sich um Dinge kümmern, die man immer nochmal machen wollte. Da ich ein Snake-Fan bin, habe ich noch eine Version geschrieben. Your browser does not support the video tag. Ich würde euch zwar gerne erzählen, dass ich die Schlange da so geschickt gesteuert habe, andererseits möchte ich auch nicht den \"Automatikmodus\" verschweigen. Im Gegensatz zum Konsolen/ncurses Snake , das in C geschrieben war, ist diese Version jetzt in Python3 mit QT4 (pyqt) als Gui Toolkit ausgestattet. Quellen auf GitHub .","tags":"Code","url":"https://blog.schawe.me/pysnake.html","loc":"https://blog.schawe.me/pysnake.html"},{"title":"Snake","text":"Und wenn ich Snake sage, meine ich das Beste, was Nokia Handys zu bieten haben. Jedenfalls vor 10 Jahren — vermutlich immer noch. Aber weil ich kein Nokia Handy habe, habe ich mir Snake schnell selbst geschrieben — in C. Jetzt gibt es eine neue Version, die auf ncurses aufsetzt. Neben der verbesserten \"Grafik\" kann man jetzt auch die Pfeiltasten zur Steuerung benutzen. Außerdem wirkt es sehr viel eleganter. Der Code ist auf GitHub .","tags":"Code","url":"https://blog.schawe.me/snake.html","loc":"https://blog.schawe.me/snake.html"},{"title":"Conway's Game of Life","text":"Damit man mental nicht ganz einrostet, habe ich gestern Abend Conway's Game of Life in C geschrieben ( GitHub ). Mit cairo (deren Logo eine stabile Konfiguration von Conway's Game of Life ist) werden die einzelnen Runden dann als .png gespeichert. Und wenn ihr selber ein paar Startkonfigurartionen schreiben wollt, sollte der Quellcode nicht allzu undurchschaubar sein. Hier ein paar Ergebnisse mit imagemagick animiert: convert -delay 20 ./*png ./out2.gif","tags":"Code","url":"https://blog.schawe.me/conways-game-of-life.html","loc":"https://blog.schawe.me/conways-game-of-life.html"},{"title":"Der grüne Punkt","text":"Das Yin und Yang der Moderne.","tags":"Misc","url":"https://blog.schawe.me/der-grune-punkt.html","loc":"https://blog.schawe.me/der-grune-punkt.html"},{"title":"Regenbogen","text":"Man sollte alles nach Wellenlänge sortieren!","tags":"misc","url":"https://blog.schawe.me/regenbogen.html","loc":"https://blog.schawe.me/regenbogen.html"},{"title":"Come to the dark side, our theme song is better","text":"Der Imperiale Marsch, gespielt auf einem Telefonlautsprecher von einem AVR ATMEGA8 . Your browser does not support the video tag. Der Code für den Microcontroller ist als Gist auf GitHub .","tags":"Tech","url":"https://blog.schawe.me/come-to-the-dark-side-our-theme-song-is-better.html","loc":"https://blog.schawe.me/come-to-the-dark-side-our-theme-song-is-better.html"},{"title":"ssh-password","text":"Um das Passwort des ssh-rsa-Schlüssels zu ändern. ssh-keygen -f id_rsa -p","tags":"Snip","url":"https://blog.schawe.me/ssh-password.html","loc":"https://blog.schawe.me/ssh-password.html"},{"title":"TicTacToe","text":"","tags":"Code","url":"https://blog.schawe.me/tictactoe.html","loc":"https://blog.schawe.me/tictactoe.html"},{"title":"Binär Uhr","text":"","tags":"Tech","url":"https://blog.schawe.me/binar-uhr.html","loc":"https://blog.schawe.me/binar-uhr.html"}]};