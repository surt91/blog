<!DOCTYPE html>

<html lang="de">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>möchte­gern­geek - Physik tag</title>
<meta content="Dinge, die ich für hübsch, praktisch oder interessant halte." name="description"/>
<meta content="Hendrik Schawe" name="author"/>
<meta content="Hendrik Schawe" name="copyright"/>
<meta content="#3d4f5d" name="theme-color"/>
<link href="/manifest.json" rel="manifest"/>
<link href="/favicon.ico" rel="icon" type="image/x-icon"/>
<!-- Add to home screen for Safari on iOS-->
<meta content="yes" name="apple-mobile-web-app-capable"/>
<meta content="default" name="apple-mobile-web-app-status-bar-style"/>
<meta content="möchtegerngeek" name="apple-mobile-web-app-title"/>
<link href="/extra/icons/icon-152x152.png" rel="apple-touch-icon"/>
<!-- Add to home screen for Windows-->
<meta content="/extra/icons/icon-152x152.png" name="msapplication-TileImage"/>
<meta content="#b0cadb" name="msapplication-TileColor"/>
<meta content="möchte­gern­geek" property="og:site_name"/>
<meta content="Hendrik Schawe" property="og:article:author"/>
<meta content="article" property="og:type"/>
<meta content="summary" name="twitter:card"/>
<meta content="https://blog.schawe.me/img/logo.png" property="og:image"/>
<meta content="https://blog.schawe.me/img/logo.png" name="twitter:image"/>
<link href="https://blog.schawe.me/tag/physik.html" hreflang="de" rel="alternate">
<link href="https://blog.schawe.me/en/tag/physik.html" hreflang="en" rel="alternate">
<link href="https://blog.schawe.me/tag/physik.html" hreflang="x-default" rel="alternate">
<link href="/theme/webassets-external/6fc8b5d0286641a8981481d8734adb14_pure-min.css" rel="stylesheet" type="text/css"/>
<link href="/theme/webassets-external/cd1fc9b8f4fd6935866873d6d3cfad1b_grids-responsive-min.css" rel="stylesheet" type="text/css"/>
<link href="/theme/css/blog.css" rel="stylesheet" type="text/css"/>
<script async="" src="/theme/js/mathjax-config.js"></script>
<script async="" crossorigin="anonymous" data-search-pseudo-elements="" integrity="sha512-RXf+QSDCUQs5uwRKaDoXt55jygZZm2V++WUZduaU/Ui/9EGp3f/2KZVahFZBKGH0s774sd3HmrhUy+SgOFQLVQ==" referrerpolicy="no-referrer" src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/js/all.min.js"></script>
<!-- Preload the other fonts early -->
<link as="font" crossorigin="anonymous" href="/theme/woff2/Merriweather-12ptRegular.woff2" rel="prefetch" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="/theme/woff2/FiraSans-Regular.woff2" rel="prefetch" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="/theme/woff2/FiraSans-Bold.woff2" rel="prefetch" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="/theme/woff2/Merriweather-12ptItalic.woff2" rel="prefetch" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="/theme/woff2/firacode-regular.woff2" rel="prefetch" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="/theme/woff2/firacode-bold.woff2" rel="prefetch" type="font/woff2"/>
<link href="https://blog.schawe.me/feeds/all.atom.xml" rel="alternate" title="möchte­gern­geek - Full Atom Feed" type="application/atom+xml">
</link></link></link></link></head>
<body>
<div class="pure-g" id="layout">
<div class="sidebar pure-u-1 pure-u-lg-1-4">
<div class="header">
<h1 class="brand-title"><a href="https://blog.schawe.me">möchte­gern­geek</a></h1>
<nav class="nav">
<ul class="nav-list container">
<li class="nav-item">
<a class="pure-button" href="https://blog.schawe.me/en/"><i class="fa fa-globe"></i> en</a>
</li>
<li class="nav-item">
<a class="pure-button" href="https://blog.schawe.me/categories.html">Kategorien</a>
</li>
<li class="nav-item">
<a class="pure-button" href="https://blog.schawe.me/tags.html">Tags</a>
</li>
<li class="nav-item">
<a class="pure-button" href="https://blog.schawe.me/archives.html">Archiv</a>
</li>
</ul>
</nav>
<div class="container">
<a class="sidebar-social-links" href="https://hendrik.schawe.me" rel="noopener" target="_blank" title="Ich">
<i class="fas fa-user sidebar-social-links"></i>
</a>
<a class="sidebar-social-links" href="https://github.com/surt91" rel="noopener" target="_blank" title="GitHub">
<i class="fab fa-github sidebar-social-links"></i>
</a>
<a class="sidebar-social-links" href="mailto:hendrik.schawe+blog@gmail.com" rel="noopener" target="_blank" title="Email">
<i class="fas fa-envelope sidebar-social-links"></i>
</a>
<a class="sidebar-social-links" href="https://twitter.com/surt91" rel="noopener" target="_blank" title="Twitter">
<i class="fab fa-twitter sidebar-social-links"></i>
</a>
</div>
<div class="container">
<form action="https://blog.schawe.me/search.html" class="pure-form">
<fieldset>
<input aria-label="Suche" class="search-query" id="tipue_search_input" name="q" placeholder="Suche" type="text"/>
</fieldset>
</form>
</div>
</div>
</div>
<div class="content pure-u-1 pure-u-lg-3-4">
<div class="posts">
<article class="post">
<header>
<h2 class="post-title">
<a href="https://blog.schawe.me/paper-convex-highdim.html"> Convex hulls of random walks in higher dimensions: A large deviation study  </a>
</h2>
<div class="post-meta">
<div>
<span class="doi-details">
                        Hendrik Schawe, Alexander K. Hartmann, Satya N. Majumdar,
                        Physical Review E <b>96</b>, 062101 (2017)
                    </span>
</div>
<time class="post-time" datetime="2022-05-28T16:08:00+02:00">28.05.2022</time>
<span class="category category-phys">
<a href="https://blog.schawe.me/categories.html#phys-ref">Phys</a>
</span>
<span class="tags-in-article">
<span class="tag">
<a href="https://blog.schawe.me/tags.html#bild-ref">Bild</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#physik-ref">Physik</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#veroffentlichung-ref">Veröffentlichung</a>
</span>
</span>
<span class="doi"><a href="https://dx.doi.org/10.1103/PhysRevE.96.062101">doi:10.1103/PhysRevE.96.062101</a></span>
</div>
</header>
<div class="post-content">
<p>Die Frage wie groß das Revier eines Tieres ist, ist in konkreten Fällen für Biologen
interessant und dank <span class="caps">GPS</span>-Sendern kann man es heutzutage sogar empirisch untersuchen. Aus der
Punktwolke der besuchten Orte kann man eine Fläche abschätzen — im einfachsten Fall
indem man die konvexe Hülle um alle besuchten Orte zeichnet.</p>
<p>Als Physiker sind mir echte Tiere zu kompliziert, sodass ich stattdessen annehme,
dass sie punktförmig sind und ihre Bewegung ein <em>Random Walk</em> in einer isotropen
Umgebung ist. Also springen meine idealisierten Tiere unabhängig von ihren bisherigen
Handlungen zu ihrem nächsten Aufenthaltsort — der Abstand vom aktuellen Punkt ist dabei
in jeder Dimension unabhängig und normalverteilt.</p>
<p><em>In jeder Dimension?</em> Ja, genau! Wir wollen schließlich auch das Revierverhalten von
vierdimensionalen Space Whales untersuchen.</p>
<p><img alt="Ein vierdimensionaler Weltraumwal, oder was Stable Diffusion sich darunter vorstellt" height="512" src="/img/SpaceWhale.webp" width="512"/></p>
<p>Spaß beiseite, in dieser Veröffentlichung geht es natürlich eher um fundamentale
Eigenschaften von Random Walks — einer der einfachsten und deshalb am besten
untersuchten Markow-Prozesse. Und zwar im Hinblick auf Large Deviations,
die extrem unwahrscheinlichen Ereignisse, die weit jenseits der Möglichkeiten
von konventionellen Sampling-Methoden liegen. Details hierzu sind am besten
direkt im <a href="https://academic.schawe.me/pdf/2017_convex_highdim_PRE.pdf">Artikel</a> oder mit einer
Menge Hintergrundinformationen und ausführlicher als für ein Blog angemessen
in dem entsprechenden Kapitel und Anhang meiner <a href="https://academic.schawe.me/pdf/dissertation.pdf">Dissertation</a>
nachzulesen. Insbesondere ist dort auch beschrieben wie die geometrischen
Unterprobleme effizient gelöst werden können, auf die wir im Verlauf dieses
Blogposts stoßen werden.</p>
<p>Das Problem eine konvexe Hülle zu finden ist einerseits einfach zu begreifen,
schön geometrisch und sehr gut untersucht. Dadurch sind überraschend viele
Algorithmen bekannt, die unterschiedliche Vor- und Nachteile haben.</p>
<p>Im Folgenden möchte ich deshalb ein paar Methoden vorstellen, wie man effizient
die konvexe Hülle einer Punktmenge bestimmen kann, und dies mit animierten gifs von
Punkten und Strichen visualisieren. Der Code zur Erstellung der Visualisierungen
ist übrigens in Rust geschrieben und auf <a href="https://github.com/surt91/convex_hulls">GitHub</a> zu finden.</p>
<h2>Andrew’s Monotone Chain</h2>
<p>In zwei Dimensionen kann man ausnutzen, dass die konvexe Hülle ein Polygon ist, das
man durch die Reihenfolge der Eckpunkte definieren kann. Die grundlegende Idee ist
also die Punkte im Uhrzeigersinn zu sortieren, in dieser Reihenfolge, mit dem
Punkt ganz links startend, alle zu einem Polygon hinzuzufügen und dabei darauf
zu achten, dass die drei neusten Punkte des Polygons ein negativ orientiertes Dreieck
bilden, also dass sie im „Uhrzeigersinn drehen“. Wenn das nicht der Fall ist,
wird der mittlere Punkt entfernt.</p>
<p><img alt="Sechs Schritte von Andrew's Monotone Chain -- oder Graham Scan" class="invertable" height="1170" src="/img/ch_andrew_steps.webp" width="3440"/></p>
<p>Dies ist übrigens die ursprüngliche Variante, der <em>Graham Scan</em>. Andrew verbesserte
diesen Algorithmus dadurch, dass nicht im Uhrzeigersinn sortiert werden muss, sondern
man lexikographisch nach horizontaler Koordinate (bei Gleichstand entscheidet die
vertikale Koordinate) sortiert. Dann bildet dieser Algorithmus die obere Hälfte der Hülle
und wenn man ihn rückwärts auf die sortierten Punkte anwendet, die untere Hälfte.</p>
<p><img alt="Andrew's Monotone Chain" class="invertable" height="800" src="/img/ch_andrew.gif" width="800"/></p>
<p>Die Komplexität für $n$ Punkte ist somit $\mathcal{O}(n \ln n)$ limitiert durch das Sortieren.</p>
<h2>Jarvis March: Gift Wrapping</h2>
<p>Ein Geschenk einzupacken ist ein relativ intuitiver Prozess: Wir bewegen das Papier
so lange herunter, bis wir auf einen Punkt des Geschenkes treffen, wo es hängen bleibt
Dann wickeln wir weiter, bis wir auf den nächsten Punkt stoßen. Dabei streben wir an die
konvexe Hülle zu finden, denn sie ist das Optimum möglichst wenig Papier zu verbrauchen
während wir die Punktwolke einhüllen, die wir verschenken wollen. Und offenbar klappt das
auch in drei Dimensionen!</p>
<p>In einem Computer ist es allerdings einfacher das Geschenkpapier von innen aus der Punktwolke
heraus nach außen zu falten. Für jede Facette testen wir also jeden der $n$ Punkte in der
Punktwolke darauf, ob er links von unserem Stück Geschenkpapier liegt. Wenn ja, falten wir das
Papier weiter. Sobald wir alle $n$ Punkte ausprobiert haben, wissen wir, dass das Geschenkpapier
an der richtigen Stelle liegt, sodass anfangen können die nächste Facette mit dem Geschenkpapier
zu bilden indem wir von innen alle Punkte durchtesten.</p>
<p><img alt="Jarvis March: Gift Wrapping" class="invertable" height="800" src="/img/ch_jarvis.gif" width="800"/></p>
<p>Interessanterweise müssen wir also für jeden der $h$ Punkte, die zur Hülle gehören $\mathcal{O}(n)$ Punkte
prüfen, sodass die Komplexität abhängig ist vom Ergebnis: $\mathcal{O}(n h)$</p>
<h2>Chan’s Algorithm</h2>
<p>Wir haben also einen $\mathcal{O}(n \ln n)$ und einen $\mathcal{O}(n h)$ Algorithmus kennen gelernt,
aber können wir noch besser werden? Ja! $\mathcal{O}(n \ln h)$ ist die theoretische untere Komplexitätsgrenze
für 2D konvexe Hüllen. Beispielsweise Chans Algorithmus erreicht diese Komplexität mit einem trickreichen
zweistufigen Prozess.</p>
<p>Zuerst teilt man die Punktwolke in zufällige Untermengen mit jeweils etwa $m$ Punkten ein. Für jede berechnet
man die konvexe Hülle, bspw. mit Andrews Algorithmus. Dann benutzt man Jarvis March, um die Hülle zu konstruieren,
dabei muss man allerdings nicht mehr alle Punkte durchprobieren, sondern nur noch die Tangenten, die in der Animation
mit grünen Strichen gekennzeichnet sind. Die Tangenten kann man für jede der $k = \lceil \frac{n}{m} \rceil$ Sub-Hüllen
effizient in $\mathcal{O}(m)$ bestimmen. Dazu benutzt man einem Algorithmus, der an eine Binärsuche erinnert.
Zusammen hat dies also eine Komplexität von $\mathcal{O}((n+kh) \ln m)$.</p>
<p>Aber ich hatte $\mathcal{O}(n \ln h)$ versprochen. Nun, um das zu erreichen, müssen wir einfach nur $m \approx h$ wählen.
Aber wie kommen wir an $h$ bevor wir die Hülle berechnet haben? Der Trick ist, mit einem niedrigen $m$ zu starten,
dann nur $m$ Schritte des Jarvis-Teils des Algorithmus durchzuführen und wenn die Hülle dann noch nicht fertig ist
$m$ zu erhöhen und es wieder von vorne zu beginnen. Damit dieser iterative Teil des Algorithmus nicht unsere Komplexität
erhöht, muss $m$ schnell genug wachsen, was in der Regel durch Quadrieren des alten Werten erreicht wird.</p>
<p><img alt="Chan's Algorithm" class="invertable" height="800" src="/img/ch_chan.gif" width="800"/></p>
<h2>QuickHull</h2>
<p>Zuletzt möchte ich hier noch QuickHull vorstellen, weil dieser Algorithmus meiner Meinung nach einen sehr hübschen
rekursiven <em>divide and conquer</em> Ansatz verfolgt — ein bisschen wie QuickSort.
In zwei Dimensionen starten wir mit dem Punkt ganz links $A$ und ganz rechts $B$. Dann finden wir den Punkt $C$ der
am weitesten entfernt ist von der Strecke $\overline{<span class="caps">AB</span>}$ und links von der Strecke ist. Diesen Schritt wiederholen wir
rekursiv auf den Strecken $\overline{<span class="caps">AC</span>}$ und $\overline{<span class="caps">CB</span>}$ (und $\overline{<span class="caps">BA</span>}$ für die untere Hälfte.)</p>
<p><img alt="QuickHull" class="invertable" height="800" src="/img/ch_quickhull.gif" width="800"/></p>
<h2>Mehr Dimensionen</h2>
<p>Aber ich hatte Space Whales versprochen, also können wir uns nicht mit 2D zufrieden geben!
Tatsächlich müssen wir schon beim Verallgemeinern auf 3D aufpassen. Schließlich konnten
wir für 2D die konvexe Hülle als Sequenz von Punkten repräsentieren. Für höhere Dimensionen
müssen wir sie allerdings als Menge von Facetten repräsentieren. Glücklicherweise tauchen
für noch höhere Dimensionen dann keine weiteren Schwierigkeiten mehr auf — abgesehen von der
Grundsätzlichen Schwierigkeit, dass höherdimensionale Gebilde deutlich größere Oberflächen
haben und somit die konvexe Hülle aus deutlich mehr Facetten besteht, sodass die untere Schranke
für die Komplexität für Dimension $d$ durch $\mathcal{O}(n^{\lfloor d / 2 \rfloor})$ gegeben ist.</p>
<p>Bevor ich hier QuickHull für $d=3$ beschreibe, möchte ich darauf hinweisen, dass es die
<a href="http://www.qhull.org/"><code>qhull</code> Implementierung</a> gibt, die sich bspw. auch um die subtilen numerischen
Fehler kümmert, die sich bei sehr spitzen Winkeln einschleichen können.</p>
<p>Grundsätzlich bleibt das Vorgehen gleich: Wir starten mit einem $d$-dimensionalen Simplex, also für $d=3$
mit einem Tetraeder, dessen Eckpunkte zur konvexen Hülle gehören. Dann führen wir für jede Facette
den rekursiven Schritt durch: Finde den Punkt, der am weitesten <em>vor</em> der Facette (also außerhalb des Tetraeders) ist.
Diesen Punkt nennt man <em>Eye-Point</em>. Denn es reicht jetzt im Gegensatz zum 2D Fall nicht mehr
einfach neue Facetten aus den Rändern und dem neuen Punkt zu bilden. Stattdessen müssen wir alle
Facetten, deren Vorderseite (also Außenseite) wir vom Eye-Point aus sehen können entfernen und
neue Facetten mit dem Horizont und dem <em>Eye-Point</em> bilden. In der Animation unten sind der <em>Eye-Point</em>
sowie die Facetten, die er sieht, rot dargestellt. Der Horizont ist mit schwarzen Strichen gekennzeichnet.</p>
<p>Wird dieser Schritt rekursiv auf alle neu hinzugefügten Facetten angewendet, resultiert die
konvexe Hülle. Und genauso, wenn auch deutlich schwieriger darstellbar, funktioniert es auch
für alle höheren Dimensionen.</p>
<p><img alt="QuickHull" height="1450" src="/img/ch_quickhull3d.gif" width="1450"/></p>
<p>Eine wichtige Anwendung für 3D konvexe Hüllen ist übrigens die Delaunay-Triangulation einer planaren
Punktmenge. Die wiederum kann für eine effiziente Berechnung des <a href="https://blog.schawe.me/relative-neighborhood-graph.html">Relative-Neighborhood-Graphs aus
diesem Post</a> genutzt werden.</p>
</div>
</article>
<article class="post">
<header>
<h2 class="post-title">
<a href="https://blog.schawe.me/more-fractals.html"> Noch mehr Fraktale  </a>
</h2>
<div class="post-meta">
<time class="post-time" datetime="2021-06-07T20:45:00+02:00">07.06.2021</time>
<span class="category category-code">
<a href="https://blog.schawe.me/categories.html#code-ref">Code</a>
</span>
<span class="tags-in-article">
<span class="tag">
<a href="https://blog.schawe.me/tags.html#bild-ref">Bild</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#chaos-ref">Chaos</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#formel-ref">Formel</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#github-ref">GitHub</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#physik-ref">Physik</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#rust-ref">Rust</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#twitter-bot-ref">Twitter-Bot</a>
</span>
</span>
</div>
</header>
<div class="post-content">
<p>Seit meinem <a href="https://blog.schawe.me/randomFractals.html">ersten Eintrag</a> über meinen
Fraktal-tweetenden Bot <a href="https://twitter.com/AFractalADay">@AFractalADay</a>,
habe ich selbigen noch um ein paar Fraktale erweitert, die ich hier kurz
festhalten möchte. Der ganze Code ist <a href="https://github.com/surt91/AFractalADay">auf Github</a>.</p>
<h3>Chaotic Maps</h3>
<p>Eine <em>Quadratic Map</em> ist eine Rekursionsgleichung mit einem quadratischen
Term, also beispielsweise
$$x_{i+1} = a_0 x^2 + a_1 x + a_2.$$
Das berühmteste Mitglied dieser Familie ist die <a href="https://de.wikipedia.org/wiki/Logistische_Gleichung"><em>Logistic-Map</em></a>
mit $a_0=1, a_1=r, a_2=0$, die chaotisches Verhalten für $3.56995 &lt; r &lt; 4$ zeigt.
Aber leider ist sie nur eindimensional und ihr Attraktor deshalb nicht besonders hübsch.</p>
<p>Um visuell ansprechende Fraktale daraus zu erzeugen, brauchen wir also ein System aus
zwei Rekursionsgleichungen, die wir als $x$- und $y$-Koordinaten betrachten können:</p>
<p>\begin{align<em>}
x_{i+1} &amp;= a_{0} + a_{1} x + a_{2} x^2 + a_{3} x y + a_{4} y + a_{5} y^2\
y_{i+1} &amp;= a_{6} + a_{7} x + a_{8} x^2 + a_{9} x y + a_{10} y + a_{11} y^2.
\end{align</em>}</p>
<p>Jetzt haben wir 12 freie Parameter, die einen riesigen Parameterraum aufspannen,
in dem <a href="http://sprott.physics.wisc.edu/pubs/paper203.htm">etwa 1.6%</a> aller Möglichkeiten
chaotisches Verhalten mit einem seltsamen Attraktor zeigen.</p>
<p><a href="/img/quadraticMap.png"><img alt="Quadratic Map" height="675" src="/img/quadraticMap1200.webp" width="1200"/></a></p>
<h3>Chaotische Differentialgleichungssysteme</h3>
<p>Ein echter Klassiker ist das Differentialgleichungssystem, das die Chaostheorie
begründet hat und nach dem der <em>Schmetterlingseffekt</em> benannt
ist [<a href="https://blog.schawe.me/schmetterlingseffekt.html">1</a>, <a href="https://blog.schawe.me/seltsamer-attraktor.html">2</a>].
Für bestimmte Paramtersätze verlaufen die Bahnkurven entlang eines <em>seltsamen Attraktors</em>,
dessen fraktale Dimension $\approx 2.06$ ist. Da der vollständige Attraktor somit in
einer zweidimensionalen Projektion <a href="/img/lorenz_full_attractor.png">etwas langweilig</a> aussieht,
habe ich hier nur eine Trajektorie über kurze Zeit dargestellt.</p>
<p><a href="/img/lorenzattraktor2.png"><img alt="Lorenz-Attraktor" height="675" src="/img/lorenzattraktor2_1200.webp" width="1200"/></a></p>
<p>Und es gibt <a href="https://en.wikipedia.org/wiki/List_of_chaotic_maps">eine ganze Menge</a>
weitere Differntialgleichungssysteme (und <em>chaotic maps</em>), die chaotische
Attraktoren aufweisen. Deshalb zeige ich hier noch einen Rössler-Attraktor, der
eine vereinfachte Version des Lorenz-Systems ist:</p>
<p>\begin{align<em>}
\frac{\mathrm{d}x}{\mathrm{d}t} &amp;= -(y+z)\
\frac{\mathrm{d}y}{\mathrm{d}t} &amp;= x + ay\
\frac{\mathrm{d}z}{\mathrm{d}t} &amp;= b + xz - cz
\end{align</em>}</p>
<p>Und hier haben wir das Glück, dass auch seine Projektion sehr ansehnlich ist.</p>
<p><a href="/img/rossler.png"><img alt="Rössler-Attraktor" height="675" src="/img/rossler1200.webp" width="1200"/></a></p>
<p>Ich persönlich frage mich, nun wie der Attraktor für das <a href="https://blog.schawe.me/double-pendulum.html">Doppelpendel</a>
aussieht. Es ist anscheinend kein Fraktal, aber es sieht dennoch ganz interessant aus:</p>
<p><a href="/img/doublePendulumLong.png"><img alt="Doppelpendel" height="1000" src="/img/doublePendulumLong1200.webp" width="1000"/></a></p>
<h3>Ising model</h3>
<p>Das Ising Modell für Ferromagnetismus wird auch als Drosophila
der statistischen Physik bezeichnet: Es ist ein einfaches
Modell, dass einen Phasenübergang aufweist — Eisen verliert
seine magnetischen Eigenschaften oberhalb der Curie-Temperatur.</p>
<p>Es besteht aus magnetischen Momenten, <em>Spins</em>, die gerne in die
gleiche Richtung zeigen wie ihre Nachbarn, aber durch hohe Temperatur
gestört werden. Oder etwas formaler: Die innere Energie $U$ wird durch
den Hamiltonian $\mathcal{H} = - \sum_{<ij>} s_i s_j$ bestimmt, wobei
$s_i = \pm 1$, je nachdem ob der Spin <em>up</em> oder <em>down</em> ist und die
Summe über benachbarte Spins läuft. Das System
wird immer einen Zustand anstreben, der die freie Energie $F=U-<span class="caps">TS</span>$
minimiert. Das kann entweder passieren, indem $U$ möglichst klein
ist oder die Entropie $S$ möglichst hoch. Bei großen Werten der
Temperatur $T$ bekommt der Entropie-Term ein höheres Gewicht, sodass
Zustände mit hoher Entropie, also zufälligen Spinausrichtungen,
bevorzugt sind, bei niedrigen Temperaturen werden Konfigurationen
mit niedriger innerer Energie bevorzugt, also solche in denen alle Spins
in die selbe Richtung zeigen. Die Temperatur, bei der sich beide
Terme die Waage halten, nennt man kritische Temperatur. Hier bilden
sich Regionen von Spins, die in die gleiche Richtung zeigen, auf allen
Größenskalen. Die fraktale Dimension dieser Regionen ist
<a href="https://doi.org/10.1103/PhysRevLett.62.1067">187/96</a>,
was solche kritische Konfigurationen interessant anzusehen macht.
Ich empfehle auf das folgende Bild zu klicken und etwas hineinzuzoomen.</ij></p>
<p><a href="/img/ising.png"><img alt="Kritisches Ising System" height="300" src="/img/ising1200.webp" width="1200"/></a></p>
</div>
</article>
<article class="post">
<header>
<h2 class="post-title">
<a href="https://blog.schawe.me/paper-lis2.html"> Number of longest increasing subsequences  </a>
</h2>
<div class="post-meta">
<div>
<span class="doi-details">
                        Phil Krabbe, Hendrik Schawe, Alexander K. Hartmann,
                        Physical Review E <b>101</b>, 062109 (2020)
                    </span>
</div>
<time class="post-time" datetime="2020-06-02T11:11:00+02:00">02.06.2020</time>
<span class="languages-in-article">
<span class="language">
<a href="https://blog.schawe.me/en/paper-lis2.html"><i class="fa fa-globe"></i> en</a>
</span>
</span>
<span class="category category-phys">
<a href="https://blog.schawe.me/categories.html#phys-ref">Phys</a>
</span>
<span class="tags-in-article">
<span class="tag">
<a href="https://blog.schawe.me/tags.html#bild-ref">Bild</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#physik-ref">Physik</a>
</span>
<span class="tag">
<a href="https://blog.schawe.me/tags.html#veroffentlichung-ref">Veröffentlichung</a>
</span>
</span>
<span class="doi"><a href="https://dx.doi.org/10.1103/PhysRevE.101.062109">doi:10.1103/PhysRevE.101.062109</a></span>
</div>
</header>
<div class="post-content">
<p>Meine liebsten Probleme sind solche, die einfach scheinen aber sehr tief sind. Natürlich gehört
das <a href="https://blog.schawe.me/paper-tsp-pt.html">Problem des Handlungsreisenden</a> dazu: Es ist einfach zu verstehen,
dass der Müllmann bei jeder Mülltonne vorbei muss und dabei möglichst wenig Strecke fahren will.
Gerade deshalb ist es das Paradebeispiel für <span class="caps">NP</span>-schwere Probleme (technisch gesehen ist nur seine
Entscheidungs-Version „Gibt es eine Tour, die kürzer ist als $X$“ <span class="caps">NP</span>-schwer und nicht die typische
Optimierungsversion: „Welche ist die kürzeste Tour“).</p>
<p>Aber fast noch besser gefällt mir das Problem der <em>längsten aufsteigenden Teilfolge</em>, oder auf englisch,
<em>longest increasing subsequence</em> (<span class="caps">LIS</span>): Gegeben eine
Folge von Zahlen $S_i$, welche Teilfolge ist am längsten unter der Bedingung, dass die Zahlen aufsteigen.</p>
<p><img alt="Eine längste aufsteigende Teilfolge ist in einer Folge markiert" class="invertable" height="68" src="img/lis_example.png" width="666"/></p>
<p>Dieses Problem ist so einfach, dass es erstmals von Stanisław Ulam als Fingerübung beschrieben wurde und nach meinem
Eindruck heutzutage als Übung für dynamische Programmierung in Universitäten verwendet wird. Wer weiß
wie viele Bewerber vor einem Whiteboard ins Schwitzen geraten sind bei dem Versuch es aus dem Stegreif zu lösen.</p>
<p><img alt="The Surprising Mathematics of Longest Increasing Subsequences -- Dan Romik" height="800" src="/img/romik.jpg" width="1200"/></p>
<p>Auf der anderen Seite ist es aber offenbar tief genug, dass man ganze Bücher darüber schreiben kann.
Es zeigen sich überraschende Querverbindungen zu scheinbar unabhängigen Problemen.
Denn die Länge $L$ der <span class="caps">LIS</span> einer Permutation fluktuiert genauso wie der <a href="https://en.wikipedia.org/wiki/Kardar%E2%80%93Parisi%E2%80%93Zhang_equation">Abstand von der Mitte zum Rand eines Kaffeeflecks</a> oder die <a href="https://www.quantamagazine.org/beyond-the-bell-curve-a-new-universal-law-20141015/">größten Eigenwerte von Zufallsmatrizen</a>.</p>
<p>Nun ist die Lösung dieses Problems nicht eindeutig: Es kann viele längste aufsteigende Teilfolgen
geben. Tatsächlich wächst die Anzahl sogar exponentiell mit der Länge der ursprünglichen Sequenz.</p>
<p><img alt="Verschiedene längste aufsteigende Teilfolgen der gleichen Folge" class="invertable" height="428" src="/img/lis_alternatives.png" width="666"/></p>
<p>Allerdings wurde bisher nie untersucht wie viele genau. Oftmals hört man, es sei nicht praktikabel
alle durchzuzählen, da es exponentiell viele seien. Und wenn es darum ginge alle zu enumerieren,
würde das stimmen. Aber wir wollen an dieser Stelle nur die Anzahl wissen, die wir mittels
dynamischer Programmierung effizient bestimmen können. Die Idee ist, dass wir für jedes Element,
das an Position $x$ in einer <span class="caps">LIS</span> auftauchen kann, berechnen, wie viele aufsteigende Teilfolgen
der Länge $L-x$ mit diesem Element beginnen.</p>
<p>Besonders einfach geht das, wenn wir zuerst eine Datenstruktur aufbauen, die kodiert welche
Elemente in einer <span class="caps">LIS</span> aufeinander folgen können. Dazu erweitern wir
<a href="https://en.wikipedia.org/wiki/Patience_sorting">Patience Sort</a>, und da dieser Algorithmus nach einem
Kartenspiel benannt ist, werden wir es auch mit Karten visualisieren: Wir schreiben jedes Element
unserer Sequenz auf eine Karte und legen die Karten auf einen Stapel, sodass das erste Element der Sequenz
oben liegt. Dann nehmen wir Karten von oben ab und legen sie auf verschiedene Stapel. Die erste Karte legen
wir auf den ersten, noch leeren Stapel. Die folgenden Karten legen wir auf den ersten Stapel, dessen
oberstes Element größer ist als die aktuelle Karte und ansonsten machen wir einen neuen Stapel rechts
davon auf. Jedes mal wenn wir eine Karte ablegen, lassen wir sie auf alle Karten, die aktuell auf dem
Vorgängerstapel liegen und kleiner sind, zeigen — dies sind die Karten die in einer aufsteigenden
längsten Teilfolge direkt vor ihr auftauchen können.</p>
<p><img alt="Animation von Patience Sort" class="invertable" height="263" src="/img/patience.gif" width="208"/></p>
<p>Am Ende haben wir $L$ Stapel, wobei $L$ die Länge der <span class="caps">LIS</span> ist, und wir können vom Stapel ganz rechts starten
und den Pfeilen folgen, um eine <span class="caps">LIS</span> zusammenzubauen. Wenn wir nur an der
<a href="https://doi.org/10.1103/PhysRevE.101.062109">Länge interessiert wären</a>, müssten wir uns über den Inhalt der Stapel keine Gedanken machen und der Algorithmus ließe sich sehr kompakt darstellen:</p>
<div class="highlight"><pre><span></span><code><span class="k">fn</span><span class="w"> </span><span class="nf">lis_len</span><span class="o">&lt;</span><span class="n">T</span><span class="p">:</span><span class="w"> </span><span class="nb">Ord</span><span class="o">&gt;</span><span class="p">(</span><span class="n">seq</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="p">[</span><span class="n">T</span><span class="p">])</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="kt">usize</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">stacks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Vec</span><span class="p">::</span><span class="n">new</span><span class="p">();</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">seq</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">pos</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stacks</span><span class="p">.</span><span class="n">binary_search</span><span class="p">(</span><span class="o">&amp;</span><span class="n">i</span><span class="p">)</span>
<span class="w">            </span><span class="p">.</span><span class="n">err</span><span class="p">()</span>
<span class="w">            </span><span class="p">.</span><span class="n">expect</span><span class="p">(</span><span class="s">"Encountered non-unique element in sequence!"</span><span class="p">);</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">pos</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">stacks</span><span class="p">.</span><span class="n">len</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">stacks</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">stacks</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">stacks</span><span class="p">.</span><span class="n">len</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div>
<p>Aber wir wollen mehr, deshalb notieren wir uns im nächsten Schritt bei allen Karten des
rechtesten Stapels wie viele aufsteigende Teilfolgen
der Länge $x=1$ mit ihnen starten, was trivialerweise je eine ist. Dann notieren wir bei allen Karten des
Stapels links davon wie viele aufsteigenden Teilfolgen der Länge 2 mit ihnen anfangen. Das können wir berechnen,
indem wir den Pfeilen rückwärts folgen und die Annotationen jeweils aufaddieren. Nachdem wir dies für
alle Stapel wiederholt haben und den linkesten Stapel beschriftet haben, können wir alle Annotationen des
linkesten Stapels aufaddieren, um die gesamte Anzahl <span class="caps">LIS</span> zu erhalten: hier $7$.</p>
<p><img alt="Beispiel der Datenstruktur zum Zählen der unterschiedlichen LIS" class="invertable" height="488" src="/img/lis_backpointer.png" width="600"/></p>
<p>Wie sich das ganze für längere Sequenzen aus unterschiedlichen Zufallsensembles im Detail verhält
haben wir in einem <a href="https://hendrik.schawe.me/pdf/2020_liscount_PRE.pdf">Artikel</a> veröffentlicht.</p>
</div>
</article>
</div>
<div class="post-navigation">
<nav class="pagination">
<a href="https://blog.schawe.me/tag/physik2.html">Älter →</a>
<br/>
            1 / 5
        </nav>
</div>
</div>
<div id="last-update">
<time datetime="2025-10-29 22:34:37">22:34:37 29.10.2025</time>
</div>
</div>
<script async="" src="/theme/webassets-external/0cf7968c252ead5c096e55c1f7673096_rythm.js"></script>
<script async="" src="/theme/webassets-external/a8b690a4c23c0610ea6538a9352534be_totally_serious_script.js"></script>
<script async="" src="/theme/js/unregister_service_worker.js"></script>
</body>
</html>